{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15799,
     "status": "ok",
     "timestamp": 1684096812734,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "xiYX33NDn5gs",
    "outputId": "016563c6-4c5c-4b0f-dd13-1270ab80265e"
   },
   "outputs": [],
   "source": [
    "# # MOUNTING GOOGLE DRIVE\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1684096813549,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "fGsDEAcerqgh",
    "outputId": "668834be-3c96-412c-ee35-0f63bfc44eb7"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getcwd())\n",
    "# print(os.listdir(\"/content/drive/MyDrive\"))\n",
    "# # https://drive.google.com/drive/folders/1SWEp8TLKBX7NfjxO77tEkmofNNQLr6GM?usp=share_link\n",
    "# wd = '/content/drive/MyDrive/CS 685/cs685_project/notebooks'\n",
    "# print(os.listdir(wd))\n",
    "# os.chdir(wd)\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15899,
     "status": "ok",
     "timestamp": 1684096829443,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "VK-iG3HctNwA",
    "outputId": "b878994a-bf56-4484-8ee3-c44528730eda"
   },
   "outputs": [],
   "source": [
    "# !pip install tokenizers\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15271,
     "status": "ok",
     "timestamp": 1684096844711,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "inZI47b6q7IX",
    "outputId": "8ee44e6a-a2ff-43c2-902d-dc3e721a1580"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AddedToken\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier_metric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cls_metric, auc_metric\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaTokenizerFast\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/utils/classifier_metric/evaluator.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, roc_auc_score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcls_metric\u001b[39m(ground_truth_labels, predict_labels):\n\u001b[1;32m      4\u001b[0m     cls_report \u001b[38;5;241m=\u001b[39m classification_report(\n\u001b[1;32m      5\u001b[0m         y_true \u001b[38;5;241m=\u001b[39m ground_truth_labels, \n\u001b[1;32m      6\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m predict_labels, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         output_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from tokenizers import AddedToken\n",
    "from utils.classifier_metric.evaluator import cls_metric, auc_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizerFast\n",
    "from utils.classifier_model import MyClassifier\n",
    "from utils.classifier_loss import ClassifierLoss\n",
    "from transformers.trainer_utils import set_seed\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from load_dataset import ColumnAndTableClassifierDataset\n",
    "# from schema_classifier import run\n",
    "\n",
    "torch.cuda.is_available(), torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1684096844712,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "sewkfmAEtl90"
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser(\"command line arguments for fine-tuning schema item classifier.\")\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=2,\n",
    "                        help='input batch size.')\n",
    "    parser.add_argument('--gradient_descent_step', type=int, default=4,\n",
    "                        help='perform gradient descent per \"gradient_descent_step\" steps.')\n",
    "    parser.add_argument('--device', type=str, default=\"3\",\n",
    "                        help='the id of used GPU device.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=3e-5,\n",
    "                        help='learning rate.')\n",
    "    parser.add_argument('--gamma', type=float, default=1.0,\n",
    "                        help='gamma parameter in the focal loss. Recommended: [0.0-2.0].')\n",
    "    parser.add_argument('--alpha', type=float, default=1.0,\n",
    "                        help='alpha parameter in the focal loss. Must between [0.0-1.0].')\n",
    "    parser.add_argument('--epochs', type=int, default=50,\n",
    "                        help='training epochs.')\n",
    "    parser.add_argument('--patience', type=int, default=32,\n",
    "                        help='patience step in early stopping. -1 means no early stopping.')\n",
    "    parser.add_argument('--seed', type=int, default=42,\n",
    "                        help='random seed.')\n",
    "    parser.add_argument('--save_path', type=str, default=\"models/schema_item_classifier\",\n",
    "                        help='save path of best fine-tuned model on validation set.')\n",
    "    parser.add_argument('--tensorboard_save_path', type=str, default=None,\n",
    "                        help='save path of tensorboard log.')\n",
    "    parser.add_argument('--train_filepath', type=str, default=\"../data/resdsql_pre/preprocessed_dataset_train.json\",\n",
    "                        help='path of pre-processed training dataset.')\n",
    "    parser.add_argument('--dev_filepath', type=str, default=\"../data/resdsql_pre/preprocessed_dataset_test.json\",\n",
    "                        help='path of pre-processed development dataset.')\n",
    "    parser.add_argument('--output_filepath', type=str, default=\"data/resdsql_pre/dataset_with_pred_probs.json\",\n",
    "                        help='path of the output dataset (used in eval mode).')\n",
    "    parser.add_argument('--model_name_or_path', type=str, default=\"roberta-large\",\n",
    "                        help='''pre-trained model name.''')\n",
    "    parser.add_argument('--use_contents', action='store_true',\n",
    "                        help='whether to integrate db contents into input sequence')\n",
    "    parser.add_argument('--add_fk_info', action='store_true',\n",
    "                        help='whether to add [FK] tokens into input sequence')\n",
    "    parser.add_argument('--mode', type=str, default=\"train\",\n",
    "                        help='trian, eval or test.')\n",
    "    parser.add_argument(\"-f\", required=False)\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def prepare_batch_inputs_and_labels(batch, tokenizer):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    batch_questions = [data[0] for data in batch]\n",
    "\n",
    "    batch_table_names = [data[1] for data in batch]\n",
    "    batch_table_labels = [data[2] for data in batch]\n",
    "\n",
    "    batch_column_infos = [data[3] for data in batch]\n",
    "    batch_column_labels = [data[4] for data in batch]\n",
    "\n",
    "    batch_input_tokens, batch_column_info_ids, batch_table_name_ids, batch_column_number_in_each_table = [], [], [], []\n",
    "    for batch_id in range(batch_size):\n",
    "        input_tokens = [batch_questions[batch_id]]\n",
    "        table_names_in_one_db = batch_table_names[batch_id]\n",
    "        column_infos_in_one_db = batch_column_infos[batch_id]\n",
    "\n",
    "        batch_column_number_in_each_table.append(\n",
    "            [len(column_infos_in_one_table) for column_infos_in_one_table in column_infos_in_one_db])\n",
    "\n",
    "        column_info_ids, table_name_ids = [], []\n",
    "\n",
    "        for table_id, table_name in enumerate(table_names_in_one_db):\n",
    "            input_tokens.append(\"|\")\n",
    "            input_tokens.append(table_name)\n",
    "            table_name_ids.append(len(input_tokens) - 1)\n",
    "            input_tokens.append(\":\")\n",
    "\n",
    "            for column_info in column_infos_in_one_db[table_id]:\n",
    "                input_tokens.append(column_info)\n",
    "                column_info_ids.append(len(input_tokens) - 1)\n",
    "                input_tokens.append(\",\")\n",
    "\n",
    "            input_tokens = input_tokens[:-1]\n",
    "\n",
    "        batch_input_tokens.append(input_tokens)\n",
    "        batch_column_info_ids.append(column_info_ids)\n",
    "        batch_table_name_ids.append(table_name_ids)\n",
    "\n",
    "    # notice: the trunction operation will discard some tables and columns that exceed the max length\n",
    "    tokenized_inputs = tokenizer(\n",
    "        batch_input_tokens,\n",
    "        return_tensors=\"pt\",\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    batch_aligned_question_ids, batch_aligned_column_info_ids, batch_aligned_table_name_ids = [], [], []\n",
    "    batch_aligned_table_labels, batch_aligned_column_labels = [], []\n",
    "\n",
    "    # align batch_question_ids, batch_column_info_ids, and batch_table_name_ids after tokenizing\n",
    "    for batch_id in range(batch_size):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=batch_id)\n",
    "\n",
    "        aligned_question_ids, aligned_table_name_ids, aligned_column_info_ids = [], [], []\n",
    "        aligned_table_labels, aligned_column_labels = [], []\n",
    "\n",
    "        # align question tokens\n",
    "        for token_id, word_id in enumerate(word_ids):\n",
    "            if word_id == 0:\n",
    "                aligned_question_ids.append(token_id)\n",
    "\n",
    "        # align table names\n",
    "        for t_id, table_name_id in enumerate(batch_table_name_ids[batch_id]):\n",
    "            temp_list = []\n",
    "            for token_id, word_id in enumerate(word_ids):\n",
    "                if table_name_id == word_id:\n",
    "                    temp_list.append(token_id)\n",
    "            # if the tokenizer doesn't discard current table name\n",
    "            if len(temp_list) != 0:\n",
    "                aligned_table_name_ids.append(temp_list)\n",
    "                aligned_table_labels.append(batch_table_labels[batch_id][t_id])\n",
    "\n",
    "        # align column names\n",
    "        for c_id, column_id in enumerate(batch_column_info_ids[batch_id]):\n",
    "            temp_list = []\n",
    "            for token_id, word_id in enumerate(word_ids):\n",
    "                if column_id == word_id:\n",
    "                    temp_list.append(token_id)\n",
    "            # if the tokenizer doesn't discard current column name\n",
    "            if len(temp_list) != 0:\n",
    "                aligned_column_info_ids.append(temp_list)\n",
    "                aligned_column_labels.append(batch_column_labels[batch_id][c_id])\n",
    "\n",
    "        batch_aligned_question_ids.append(aligned_question_ids)\n",
    "        batch_aligned_table_name_ids.append(aligned_table_name_ids)\n",
    "        batch_aligned_column_info_ids.append(aligned_column_info_ids)\n",
    "        batch_aligned_table_labels.append(aligned_table_labels)\n",
    "        batch_aligned_column_labels.append(aligned_column_labels)\n",
    "\n",
    "    # update column number in each table (because some tables and columns are discarded)\n",
    "    for batch_id in range(batch_size):\n",
    "        if len(batch_column_number_in_each_table[batch_id]) > len(batch_aligned_table_labels[batch_id]):\n",
    "            batch_column_number_in_each_table[batch_id] = batch_column_number_in_each_table[batch_id][\n",
    "                                                          : len(batch_aligned_table_labels[batch_id])]\n",
    "\n",
    "        if sum(batch_column_number_in_each_table[batch_id]) > len(batch_aligned_column_labels[batch_id]):\n",
    "            truncated_column_number = sum(batch_column_number_in_each_table[batch_id]) - len(\n",
    "                batch_aligned_column_labels[batch_id])\n",
    "            batch_column_number_in_each_table[batch_id][-1] -= truncated_column_number\n",
    "\n",
    "    encoder_input_ids = tokenized_inputs[\"input_ids\"]\n",
    "    encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"]\n",
    "    batch_aligned_column_labels = [torch.LongTensor(column_labels) for column_labels in batch_aligned_column_labels]\n",
    "    batch_aligned_table_labels = [torch.LongTensor(table_labels) for table_labels in batch_aligned_table_labels]\n",
    "\n",
    "    # print(\"\\n\".join(tokenizer.batch_decode(encoder_input_ids, skip_special_tokens = True)))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        encoder_input_ids = encoder_input_ids.cuda()\n",
    "        encoder_input_attention_mask = encoder_input_attention_mask.cuda()\n",
    "        batch_aligned_column_labels = [column_labels.cuda() for column_labels in batch_aligned_column_labels]\n",
    "        batch_aligned_table_labels = [table_labels.cuda() for table_labels in batch_aligned_table_labels]\n",
    "\n",
    "    return encoder_input_ids, encoder_input_attention_mask, \\\n",
    "        batch_aligned_column_labels, batch_aligned_table_labels, \\\n",
    "        batch_aligned_question_ids, batch_aligned_column_info_ids, \\\n",
    "        batch_aligned_table_name_ids, batch_column_number_in_each_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "\n",
    "total_table_pred_probs, total_column_pred_probs = _test(opt)\n",
    "\n",
    "with open(opt.dev_filepath, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# record predicted probability\n",
    "truncated_data_info = []\n",
    "for data_id, data in enumerate(dataset):\n",
    "    table_num = len(data[\"table_labels\"])\n",
    "    if table_num == len(total_table_pred_probs[data_id]):\n",
    "        table_pred_probs = total_table_pred_probs[data_id]\n",
    "    else:\n",
    "        table_pred_probs = total_table_pred_probs[data_id] + [-1 for _ in range(\n",
    "            table_num - len(total_table_pred_probs[data_id]))]\n",
    "\n",
    "    truncated_table_ids = []\n",
    "    column_pred_probs = []\n",
    "    for table_id in range(table_num):\n",
    "        if table_id >= len(total_column_pred_probs[data_id]):\n",
    "            truncated_table_ids.append(table_id)\n",
    "            column_pred_probs.append([-1 for _ in range(len(data[\"column_labels\"][table_id]))])\n",
    "            continue\n",
    "        if len(total_column_pred_probs[data_id][table_id]) == len(data[\"column_labels\"][table_id]):\n",
    "            column_pred_probs.append(total_column_pred_probs[data_id][table_id])\n",
    "        else:\n",
    "            truncated_table_ids.append(table_id)\n",
    "            truncated_column_num = len(data[\"column_labels\"][table_id]) - len(\n",
    "                total_column_pred_probs[data_id][table_id])\n",
    "            column_pred_probs.append(\n",
    "                total_column_pred_probs[data_id][table_id] + [-1 for _ in range(truncated_column_num)])\n",
    "\n",
    "    data[\"column_pred_probs\"] = column_pred_probs\n",
    "    data[\"table_pred_probs\"] = table_pred_probs\n",
    "\n",
    "    if len(truncated_table_ids) > 0:\n",
    "        truncated_data_info.append([data_id, truncated_table_ids])\n",
    "\n",
    "# additionally, we need to consider and predict discarded tables and columns\n",
    "while len(truncated_data_info) != 0:\n",
    "    truncated_dataset = []\n",
    "    for truncated_data_id, truncated_table_ids in truncated_data_info:\n",
    "        print(dataset[truncated_data_id][\"question\"])\n",
    "        truncated_data = deepcopy(dataset[truncated_data_id])\n",
    "        truncated_data[\"db_schema\"] = [truncated_data[\"db_schema\"][table_id] for table_id in\n",
    "                                        truncated_table_ids]\n",
    "        truncated_data[\"table_labels\"] = [truncated_data[\"table_labels\"][table_id] for table_id in\n",
    "                                          truncated_table_ids]\n",
    "        truncated_data[\"column_labels\"] = [truncated_data[\"column_labels\"][table_id] for table_id in\n",
    "                                            truncated_table_ids]\n",
    "        truncated_data[\"table_pred_probs\"] = [truncated_data[\"table_pred_probs\"][table_id] for table_id in\n",
    "                                              truncated_table_ids]\n",
    "        truncated_data[\"column_pred_probs\"] = [truncated_data[\"column_pred_probs\"][table_id] for table_id in\n",
    "                                                truncated_table_ids]\n",
    "\n",
    "        truncated_dataset.append(truncated_data)\n",
    "\n",
    "    with open(\"./data/resdsql_pre/truncated_dataset.json\", \"w\") as f:\n",
    "        f.write(json.dumps(truncated_dataset, indent=2))\n",
    "\n",
    "    opt.dev_filepath = \"./data/resdsql_pre/truncated_dataset.json\"\n",
    "    total_table_pred_probs, total_column_pred_probs = _test(opt)\n",
    "\n",
    "    for data_id, data in enumerate(truncated_dataset):\n",
    "        table_num = len(data[\"table_labels\"])\n",
    "        if table_num == len(total_table_pred_probs[data_id]):\n",
    "            table_pred_probs = total_table_pred_probs[data_id]\n",
    "        else:\n",
    "            table_pred_probs = total_table_pred_probs[data_id] + [-1 for _ in range(\n",
    "                table_num - len(total_table_pred_probs[data_id]))]\n",
    "\n",
    "        column_pred_probs = []\n",
    "        for table_id in range(table_num):\n",
    "            if table_id >= len(total_column_pred_probs[data_id]):\n",
    "                column_pred_probs.append([-1 for _ in range(len(data[\"column_labels\"][table_id]))])\n",
    "                continue\n",
    "            if len(total_column_pred_probs[data_id][table_id]) == len(data[\"column_labels\"][table_id]):\n",
    "                column_pred_probs.append(total_column_pred_probs[data_id][table_id])\n",
    "            else:\n",
    "                truncated_column_num = len(data[\"column_labels\"][table_id]) - len(\n",
    "                    total_column_pred_probs[data_id][table_id])\n",
    "                column_pred_probs.append(\n",
    "                    total_column_pred_probs[data_id][table_id] + [-1 for _ in range(truncated_column_num)])\n",
    "\n",
    "        # fill the predicted probability into the dataset\n",
    "        truncated_data_id = truncated_data_info[data_id][0]\n",
    "        truncated_table_ids = truncated_data_info[data_id][1]\n",
    "        for idx, truncated_table_id in enumerate(truncated_table_ids):\n",
    "            dataset[truncated_data_id][\"table_pred_probs\"][truncated_table_id] = table_pred_probs[idx]\n",
    "            dataset[truncated_data_id][\"column_pred_probs\"][truncated_table_id] = column_pred_probs[idx]\n",
    "\n",
    "    # check if there are tables and columns in the new dataset that have not yet been predicted\n",
    "    truncated_data_info = []\n",
    "    for data_id, data in enumerate(dataset):\n",
    "        table_num = len(data[\"table_labels\"])\n",
    "\n",
    "        truncated_table_ids = []\n",
    "        for table_id in range(table_num):\n",
    "            # the current table is not predicted\n",
    "            if data[\"table_pred_probs\"][table_id] == -1:\n",
    "                truncated_table_ids.append(table_id)\n",
    "            # some columns in the current table are not predicted\n",
    "            if data[\"table_pred_probs\"][table_id] != -1 and -1 in data[\"column_pred_probs\"][table_id]:\n",
    "                truncated_table_ids.append(table_id)\n",
    "\n",
    "        if len(truncated_table_ids) > 0:\n",
    "            truncated_data_info.append([data_id, truncated_table_ids])\n",
    "\n",
    "    os.remove(\"./data/resdsql_pre/truncated_dataset.json\")\n",
    "\n",
    "with open(opt.output_filepath, \"w\") as f:\n",
    "    f.write(json.dumps(dataset, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1684096844712,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "V9maWrzbts7O"
   },
   "outputs": [],
   "source": [
    "def _train(opt):\n",
    "    print(opt)\n",
    "    set_seed(opt.seed)\n",
    "\n",
    "    patience = opt.patience if opt.patience > 0 else float('inf')\n",
    "\n",
    "    if opt.tensorboard_save_path is not None:\n",
    "        writer = SummaryWriter(opt.tensorboard_save_path)\n",
    "    else:\n",
    "        writer = None\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.device\n",
    "    print(opt.device)\n",
    "\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "        opt.model_name_or_path,\n",
    "        add_prefix_space=True\n",
    "    )\n",
    "    tokenizer.add_tokens(AddedToken(\"[FK]\"))\n",
    "\n",
    "    train_dataset = ColumnAndTableClassifierDataset(\n",
    "        dir_=opt.train_filepath,\n",
    "        use_contents=opt.use_contents,\n",
    "        add_fk_info=opt.add_fk_info\n",
    "    )\n",
    "\n",
    "    train_dataloder = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=opt.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: x\n",
    "    )\n",
    "\n",
    "    # initialize model\n",
    "    model = MyClassifier(\n",
    "        model_name_or_path=opt.model_name_or_path,\n",
    "        vocab_size=len(tokenizer),\n",
    "        mode=opt.mode\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Model is running on cuda\")\n",
    "        model = model.cuda()\n",
    "        # device_name = torch.cuda.get_device_name()\n",
    "        # n_gpu = torch.cuda.device_count()\n",
    "        # print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "\n",
    "    # warm up steps (10% training step)\n",
    "    num_warmup_steps = int(0.1 * opt.epochs * len(train_dataset) / opt.batch_size)\n",
    "    # total training steps\n",
    "    num_training_steps = int(opt.epochs * len(train_dataset) / opt.batch_size)\n",
    "    # evaluate model for each 1.42857 epochs (about 1.42857*7000=10000 examples for Spider)\n",
    "    num_checkpoint_steps = int(1.42857 * len(train_dataset) / opt.batch_size)\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        params=model.parameters(),\n",
    "        lr=opt.learning_rate\n",
    "    )\n",
    "\n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    best_score, early_stop_step, train_step = 0, 0, 0\n",
    "    encoder_loss_func = ClassifierLoss(alpha=opt.alpha, gamma=opt.gamma)\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    for epoch in range(opt.epochs):\n",
    "        print(f\"This is epoch {epoch + 1}.\")\n",
    "        for batch in tqdm(train_dataloder):\n",
    "            model.train()\n",
    "            train_step += 1\n",
    "\n",
    "            encoder_input_ids, encoder_input_attention_mask, \\\n",
    "                batch_column_labels, batch_table_labels, batch_aligned_question_ids, \\\n",
    "                batch_aligned_column_info_ids, batch_aligned_table_name_ids, \\\n",
    "                batch_column_number_in_each_table = prepare_batch_inputs_and_labels(batch, tokenizer)\n",
    "\n",
    "            model_outputs = model(\n",
    "                encoder_input_ids,\n",
    "                encoder_input_attention_mask,\n",
    "                batch_aligned_question_ids,\n",
    "                batch_aligned_column_info_ids,\n",
    "                batch_aligned_table_name_ids,\n",
    "                batch_column_number_in_each_table\n",
    "            )\n",
    "\n",
    "            loss = encoder_loss_func.compute_loss(\n",
    "                model_outputs[\"batch_table_name_cls_logits\"],\n",
    "                batch_table_labels,\n",
    "                model_outputs[\"batch_column_info_cls_logits\"],\n",
    "                batch_column_labels\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # update lr\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            if writer is not None:\n",
    "                # record training loss (tensorboard)\n",
    "                writer.add_scalar('train loss', loss.item(), train_step)\n",
    "                # record learning rate (tensorboard)\n",
    "                writer.add_scalar('train lr', optimizer.state_dict()['param_groups'][0]['lr'], train_step)\n",
    "\n",
    "            if train_step % opt.gradient_descent_step == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if early_stop_step >= patience:\n",
    "                break\n",
    "\n",
    "        if early_stop_step >= patience:\n",
    "            print(\"Classifier training process triggers early stopping.\")\n",
    "            break\n",
    "\n",
    "    print(\"best auc score:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "615edf528d1a442cb9dba483f61ec784",
      "78789c5f09924ee4b4429ed24212038d",
      "9b4403a7ba2a49f783acb5c7769e1f8a",
      "7c34c934e74b46b7897817da166470eb",
      "a0016db1841c4fa4ab0b50580799fdc7",
      "2d986c6df88f45c6aff2d487aad2ee94",
      "2641680cb8424200a2222daaa9934cf7",
      "24840732890748c5b6d368e4c323257f",
      "59184e08e2f94380a98b6190ec77944c",
      "0a58d71c498a4ab1944642cea5d823b5",
      "c31419c019c34e17bfc496c84b250520",
      "bdef5d98c35c4ee9afa4ec61f8ead578",
      "192f55cb455941b0bf7ddc21af6bd2e4",
      "510b3d9831ca4105a1149e861822125d",
      "39fcd404fd7545d4ab2715580dbfac99",
      "26ac90e67d8f4a71bb8d0c2d82dd60e0",
      "0398a567dfa946ab861d6cf0e8870e14",
      "c1043f85129e4561a91705df31ad7b78",
      "4933a368032847c5922882a79aee0022",
      "efe1350ee5424d1e8a6f751111ca3a90",
      "7f658ae2f3254284b6169df542675de4",
      "0fdb99c5545b41438078e330b34a23f0",
      "cc147dcd25784bf1a02121b741bf1eb7",
      "36a6f08e1429400d9cb25d2ab1a9e7fc",
      "f1ba71905be44aeca6f1332b98fdef21",
      "820d0807caf049c49f95fa70fa8ce31b",
      "c2b801449aed4984967183b8b9d6cafe",
      "9e005c33cd0c4ee1a0414d8e246375b2",
      "d7065ca5bde244a8b4e031bfd559e3a9",
      "27a017d1fc8e482096c39e9d61163ddc",
      "46c66efd3ff543abbbc00762ee5ea9ef",
      "abdabb91c3de4536ab73455a80124231",
      "6d7a75cac7dc43aa837667594e200f95",
      "cf50c3d2b44447299e9a69000fcb9cce",
      "28f6ac2b157e491e98b35911ac02da3c",
      "433a693aa0d64a61ba62bf05942c628a",
      "a34e0d35cfca4b788cff833290f4ad97",
      "29fc713910154ea8a126c03ac6c34428",
      "16bc8234e0fc4ef29081acf4f89eae0a",
      "f0b2cd67041b4e2599c568150197b341",
      "e7708ac4f1d84c57b29d96cb403003e7",
      "37b9e03ae69247649131bb7df2091132",
      "7c41185c193847ed8e3d7b7ffd3927b3",
      "2f03a0cf0c3740d6b0239b1cb155657e",
      "6a1482c4ffbd49baa899f6a171688d9e",
      "e4175872de854b8f9005cf440fadb2c9",
      "7563c06e730444f2b297e4b8f6ddcd1e",
      "67ee2dffc2a34b538124b26fa9d00840",
      "3ec176d17c3b46fdb3d25c55e5254b66",
      "3be2791b1d6c4854bc6371beaa74a5fa",
      "cb6dfba869ef43c8ba3e70878ea4eb9b",
      "7d3bd53ac070444cac5e3a1890a39603",
      "f8451def606f47d8a701247d6d0bca38",
      "f3975a3e2aed471fb29c3a5ac33972bb",
      "8b414f45d6cd4857952751ba7902e71c"
     ]
    },
    "executionInfo": {
     "elapsed": 96652,
     "status": "error",
     "timestamp": 1684096941346,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "v0eU0WlL8XGk",
    "outputId": "4353f54d-efc7-4a06-b0e3-7c60ec6100ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=2, gradient_descent_step=4, device='3', learning_rate=3e-05, gamma=1.0, alpha=1.0, epochs=50, patience=32, seed=42, save_path='models/schema_item_classifier', tensorboard_save_path=None, train_filepath='../data/resdsql_pre/preprocessed_dataset_train.json', dev_filepath='../data/resdsql_pre/preprocessed_dataset_test.json', output_filepath='data/resdsql_pre/dataset_with_pred_probs.json', model_name_or_path='roberta-large', use_contents=False, add_fk_info=False, mode='train', f='/root/.local/share/jupyter/runtime/kernel-8b44a98d-b4e0-4a32-9462-cb2c5825b46a.json')\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615edf528d1a442cb9dba483f61ec784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdef5d98c35c4ee9afa4ec61f8ead578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc147dcd25784bf1a02121b741bf1eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf50c3d2b44447299e9a69000fcb9cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1482c4ffbd49baa899f6a171688d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is running on cuda\n",
      "This is epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3152 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  2%|▏         | 74/3152 [00:57<39:44,  1.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-00784fe8ab49>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-489fbe80d62a>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mbatch_column_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_table_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_aligned_question_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mbatch_aligned_column_info_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_aligned_table_name_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mbatch_column_number_in_each_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_batch_inputs_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             model_outputs = model(\n",
      "\u001b[0;32m<ipython-input-5-04545445cd06>\u001b[0m in \u001b[0;36mprepare_batch_inputs_and_labels\u001b[0;34m(batch, tokenizer)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mencoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mencoder_input_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mbatch_aligned_column_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumn_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_aligned_column_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = parse_option()\n",
    "_train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "executionInfo": {
     "elapsed": 3613777,
     "status": "error",
     "timestamp": 1684080375793,
     "user": {
      "displayName": "Atharva Nijasure",
      "userId": "14357281965942121974"
     },
     "user_tz": 240
    },
    "id": "xxVga_KMt3-A",
    "outputId": "8d51eb61-ccfa-4bce-9318-23a15a36659c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=2, gradient_descent_step=4, device='3', learning_rate=3e-05, gamma=1.0, alpha=1.0, epochs=50, patience=32, seed=42, save_path='models/schema_item_classifier', tensorboard_save_path=None, train_filepath='data/resdsql_pre/preprocessed_dataset_train.json', dev_filepath='data/resdsql_pre/preprocessed_dataset_test.json', output_filepath='data/resdsql_pre/dataset_with_pred_probs.json', model_name_or_path='roberta-large', use_contents=False, add_fk_info=False, mode='train', f='/root/.local/share/jupyter/runtime/kernel-f12ce7a3-ce04-43e2-b6e7-cb4f46f8d7a7.json')\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch 2.\n",
      "At 4502 training step, start an evaluation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-28dfbf346870>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtotal_table_pred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_column_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ac8f15498657>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# calculate AUC score for table classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mtable_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_labels_for_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_pred_probs_for_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;31m# calculate AUC score for column classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mcolumn_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_labels_for_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_pred_probs_for_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/utils/classifier_metric/evaluator.py\u001b[0m in \u001b[0;36mauc_metric\u001b[0;34m(ground_truth_labels, predict_probs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauc_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     if y_type == \"multiclass\" or (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# assert torch.cuda.is_available()\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# if __name__ == \"__main__\":\n",
    "opt = parse_option()\n",
    "if opt.mode == \"train\":\n",
    "    _train(opt)\n",
    "elif opt.mode in [\"eval\", \"test\"]:\n",
    "    total_table_pred_probs, total_column_pred_probs = _test(opt)\n",
    "\n",
    "    with open(opt.dev_filepath, \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    # record predicted probability\n",
    "    truncated_data_info = []\n",
    "    for data_id, data in enumerate(dataset):\n",
    "        table_num = len(data[\"table_labels\"])\n",
    "        if table_num == len(total_table_pred_probs[data_id]):\n",
    "            table_pred_probs = total_table_pred_probs[data_id]\n",
    "        else:\n",
    "            table_pred_probs = total_table_pred_probs[data_id] + [-1 for _ in range(\n",
    "                table_num - len(total_table_pred_probs[data_id]))]\n",
    "\n",
    "        truncated_table_ids = []\n",
    "        column_pred_probs = []\n",
    "        for table_id in range(table_num):\n",
    "            if table_id >= len(total_column_pred_probs[data_id]):\n",
    "                truncated_table_ids.append(table_id)\n",
    "                column_pred_probs.append([-1 for _ in range(len(data[\"column_labels\"][table_id]))])\n",
    "                continue\n",
    "            if len(total_column_pred_probs[data_id][table_id]) == len(data[\"column_labels\"][table_id]):\n",
    "                column_pred_probs.append(total_column_pred_probs[data_id][table_id])\n",
    "            else:\n",
    "                truncated_table_ids.append(table_id)\n",
    "                truncated_column_num = len(data[\"column_labels\"][table_id]) - len(\n",
    "                    total_column_pred_probs[data_id][table_id])\n",
    "                column_pred_probs.append(\n",
    "                    total_column_pred_probs[data_id][table_id] + [-1 for _ in range(truncated_column_num)])\n",
    "\n",
    "        data[\"column_pred_probs\"] = column_pred_probs\n",
    "        data[\"table_pred_probs\"] = table_pred_probs\n",
    "\n",
    "        if len(truncated_table_ids) > 0:\n",
    "            truncated_data_info.append([data_id, truncated_table_ids])\n",
    "\n",
    "    # additionally, we need to consider and predict discarded tables and columns\n",
    "    while len(truncated_data_info) != 0:\n",
    "        truncated_dataset = []\n",
    "        for truncated_data_id, truncated_table_ids in truncated_data_info:\n",
    "            print(dataset[truncated_data_id][\"question\"])\n",
    "            truncated_data = deepcopy(dataset[truncated_data_id])\n",
    "            truncated_data[\"db_schema\"] = [truncated_data[\"db_schema\"][table_id] for table_id in\n",
    "                                            truncated_table_ids]\n",
    "            truncated_data[\"table_labels\"] = [truncated_data[\"table_labels\"][table_id] for table_id in\n",
    "                                              truncated_table_ids]\n",
    "            truncated_data[\"column_labels\"] = [truncated_data[\"column_labels\"][table_id] for table_id in\n",
    "                                                truncated_table_ids]\n",
    "            truncated_data[\"table_pred_probs\"] = [truncated_data[\"table_pred_probs\"][table_id] for table_id in\n",
    "                                                  truncated_table_ids]\n",
    "            truncated_data[\"column_pred_probs\"] = [truncated_data[\"column_pred_probs\"][table_id] for table_id in\n",
    "                                                    truncated_table_ids]\n",
    "\n",
    "            truncated_dataset.append(truncated_data)\n",
    "\n",
    "        with open(\"./data/resdsql_pre/truncated_dataset.json\", \"w\") as f:\n",
    "            f.write(json.dumps(truncated_dataset, indent=2))\n",
    "\n",
    "        opt.dev_filepath = \"./data/resdsql_pre/truncated_dataset.json\"\n",
    "        total_table_pred_probs, total_column_pred_probs = _test(opt)\n",
    "\n",
    "        for data_id, data in enumerate(truncated_dataset):\n",
    "            table_num = len(data[\"table_labels\"])\n",
    "            if table_num == len(total_table_pred_probs[data_id]):\n",
    "                table_pred_probs = total_table_pred_probs[data_id]\n",
    "            else:\n",
    "                table_pred_probs = total_table_pred_probs[data_id] + [-1 for _ in range(\n",
    "                    table_num - len(total_table_pred_probs[data_id]))]\n",
    "\n",
    "            column_pred_probs = []\n",
    "            for table_id in range(table_num):\n",
    "                if table_id >= len(total_column_pred_probs[data_id]):\n",
    "                    column_pred_probs.append([-1 for _ in range(len(data[\"column_labels\"][table_id]))])\n",
    "                    continue\n",
    "                if len(total_column_pred_probs[data_id][table_id]) == len(data[\"column_labels\"][table_id]):\n",
    "                    column_pred_probs.append(total_column_pred_probs[data_id][table_id])\n",
    "                else:\n",
    "                    truncated_column_num = len(data[\"column_labels\"][table_id]) - len(\n",
    "                        total_column_pred_probs[data_id][table_id])\n",
    "                    column_pred_probs.append(\n",
    "                        total_column_pred_probs[data_id][table_id] + [-1 for _ in range(truncated_column_num)])\n",
    "\n",
    "            # fill the predicted probability into the dataset\n",
    "            truncated_data_id = truncated_data_info[data_id][0]\n",
    "            truncated_table_ids = truncated_data_info[data_id][1]\n",
    "            for idx, truncated_table_id in enumerate(truncated_table_ids):\n",
    "                dataset[truncated_data_id][\"table_pred_probs\"][truncated_table_id] = table_pred_probs[idx]\n",
    "                dataset[truncated_data_id][\"column_pred_probs\"][truncated_table_id] = column_pred_probs[idx]\n",
    "\n",
    "        # check if there are tables and columns in the new dataset that have not yet been predicted\n",
    "        truncated_data_info = []\n",
    "        for data_id, data in enumerate(dataset):\n",
    "            table_num = len(data[\"table_labels\"])\n",
    "\n",
    "            truncated_table_ids = []\n",
    "            for table_id in range(table_num):\n",
    "                # the current table is not predicted\n",
    "                if data[\"table_pred_probs\"][table_id] == -1:\n",
    "                    truncated_table_ids.append(table_id)\n",
    "                # some columns in the current table are not predicted\n",
    "                if data[\"table_pred_probs\"][table_id] != -1 and -1 in data[\"column_pred_probs\"][table_id]:\n",
    "                    truncated_table_ids.append(table_id)\n",
    "\n",
    "            if len(truncated_table_ids) > 0:\n",
    "                truncated_data_info.append([data_id, truncated_table_ids])\n",
    "\n",
    "        os.remove(\"./data/resdsql_pre/truncated_dataset.json\")\n",
    "\n",
    "    with open(opt.output_filepath, \"w\") as f:\n",
    "        f.write(json.dumps(dataset, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RagDh6xuvOIu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1aEzbMX02spKLcaNkP_oQ8fuggSb8pvQT",
     "timestamp": 1684095622702
    },
    {
     "file_id": "1Ej4OwQOLiVO1T10vVqqq_nwckAnTaoow",
     "timestamp": 1684090630692
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0398a567dfa946ab861d6cf0e8870e14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a58d71c498a4ab1944642cea5d823b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fdb99c5545b41438078e330b34a23f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16bc8234e0fc4ef29081acf4f89eae0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "192f55cb455941b0bf7ddc21af6bd2e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0398a567dfa946ab861d6cf0e8870e14",
      "placeholder": "​",
      "style": "IPY_MODEL_c1043f85129e4561a91705df31ad7b78",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "24840732890748c5b6d368e4c323257f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2641680cb8424200a2222daaa9934cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26ac90e67d8f4a71bb8d0c2d82dd60e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27a017d1fc8e482096c39e9d61163ddc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f6ac2b157e491e98b35911ac02da3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16bc8234e0fc4ef29081acf4f89eae0a",
      "placeholder": "​",
      "style": "IPY_MODEL_f0b2cd67041b4e2599c568150197b341",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "29fc713910154ea8a126c03ac6c34428": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d986c6df88f45c6aff2d487aad2ee94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f03a0cf0c3740d6b0239b1cb155657e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36a6f08e1429400d9cb25d2ab1a9e7fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e005c33cd0c4ee1a0414d8e246375b2",
      "placeholder": "​",
      "style": "IPY_MODEL_d7065ca5bde244a8b4e031bfd559e3a9",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "37b9e03ae69247649131bb7df2091132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39fcd404fd7545d4ab2715580dbfac99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f658ae2f3254284b6169df542675de4",
      "placeholder": "​",
      "style": "IPY_MODEL_0fdb99c5545b41438078e330b34a23f0",
      "value": " 456k/456k [00:00&lt;00:00, 15.2MB/s]"
     }
    },
    "3be2791b1d6c4854bc6371beaa74a5fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ec176d17c3b46fdb3d25c55e5254b66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "433a693aa0d64a61ba62bf05942c628a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7708ac4f1d84c57b29d96cb403003e7",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37b9e03ae69247649131bb7df2091132",
      "value": 482
     }
    },
    "46c66efd3ff543abbbc00762ee5ea9ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4933a368032847c5922882a79aee0022": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "510b3d9831ca4105a1149e861822125d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4933a368032847c5922882a79aee0022",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_efe1350ee5424d1e8a6f751111ca3a90",
      "value": 456318
     }
    },
    "59184e08e2f94380a98b6190ec77944c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "615edf528d1a442cb9dba483f61ec784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78789c5f09924ee4b4429ed24212038d",
       "IPY_MODEL_9b4403a7ba2a49f783acb5c7769e1f8a",
       "IPY_MODEL_7c34c934e74b46b7897817da166470eb"
      ],
      "layout": "IPY_MODEL_a0016db1841c4fa4ab0b50580799fdc7"
     }
    },
    "67ee2dffc2a34b538124b26fa9d00840": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3975a3e2aed471fb29c3a5ac33972bb",
      "placeholder": "​",
      "style": "IPY_MODEL_8b414f45d6cd4857952751ba7902e71c",
      "value": " 1.43G/1.43G [00:13&lt;00:00, 27.2MB/s]"
     }
    },
    "6a1482c4ffbd49baa899f6a171688d9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4175872de854b8f9005cf440fadb2c9",
       "IPY_MODEL_7563c06e730444f2b297e4b8f6ddcd1e",
       "IPY_MODEL_67ee2dffc2a34b538124b26fa9d00840"
      ],
      "layout": "IPY_MODEL_3ec176d17c3b46fdb3d25c55e5254b66"
     }
    },
    "6d7a75cac7dc43aa837667594e200f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7563c06e730444f2b297e4b8f6ddcd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d3bd53ac070444cac5e3a1890a39603",
      "max": 1425941629,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8451def606f47d8a701247d6d0bca38",
      "value": 1425941629
     }
    },
    "78789c5f09924ee4b4429ed24212038d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d986c6df88f45c6aff2d487aad2ee94",
      "placeholder": "​",
      "style": "IPY_MODEL_2641680cb8424200a2222daaa9934cf7",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "7c34c934e74b46b7897817da166470eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a58d71c498a4ab1944642cea5d823b5",
      "placeholder": "​",
      "style": "IPY_MODEL_c31419c019c34e17bfc496c84b250520",
      "value": " 899k/899k [00:00&lt;00:00, 8.71MB/s]"
     }
    },
    "7c41185c193847ed8e3d7b7ffd3927b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d3bd53ac070444cac5e3a1890a39603": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f658ae2f3254284b6169df542675de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "820d0807caf049c49f95fa70fa8ce31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abdabb91c3de4536ab73455a80124231",
      "placeholder": "​",
      "style": "IPY_MODEL_6d7a75cac7dc43aa837667594e200f95",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 11.4MB/s]"
     }
    },
    "8b414f45d6cd4857952751ba7902e71c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b4403a7ba2a49f783acb5c7769e1f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24840732890748c5b6d368e4c323257f",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59184e08e2f94380a98b6190ec77944c",
      "value": 898823
     }
    },
    "9e005c33cd0c4ee1a0414d8e246375b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0016db1841c4fa4ab0b50580799fdc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a34e0d35cfca4b788cff833290f4ad97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c41185c193847ed8e3d7b7ffd3927b3",
      "placeholder": "​",
      "style": "IPY_MODEL_2f03a0cf0c3740d6b0239b1cb155657e",
      "value": " 482/482 [00:00&lt;00:00, 37.0kB/s]"
     }
    },
    "abdabb91c3de4536ab73455a80124231": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdef5d98c35c4ee9afa4ec61f8ead578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_192f55cb455941b0bf7ddc21af6bd2e4",
       "IPY_MODEL_510b3d9831ca4105a1149e861822125d",
       "IPY_MODEL_39fcd404fd7545d4ab2715580dbfac99"
      ],
      "layout": "IPY_MODEL_26ac90e67d8f4a71bb8d0c2d82dd60e0"
     }
    },
    "c1043f85129e4561a91705df31ad7b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2b801449aed4984967183b8b9d6cafe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c31419c019c34e17bfc496c84b250520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb6dfba869ef43c8ba3e70878ea4eb9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc147dcd25784bf1a02121b741bf1eb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36a6f08e1429400d9cb25d2ab1a9e7fc",
       "IPY_MODEL_f1ba71905be44aeca6f1332b98fdef21",
       "IPY_MODEL_820d0807caf049c49f95fa70fa8ce31b"
      ],
      "layout": "IPY_MODEL_c2b801449aed4984967183b8b9d6cafe"
     }
    },
    "cf50c3d2b44447299e9a69000fcb9cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28f6ac2b157e491e98b35911ac02da3c",
       "IPY_MODEL_433a693aa0d64a61ba62bf05942c628a",
       "IPY_MODEL_a34e0d35cfca4b788cff833290f4ad97"
      ],
      "layout": "IPY_MODEL_29fc713910154ea8a126c03ac6c34428"
     }
    },
    "d7065ca5bde244a8b4e031bfd559e3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4175872de854b8f9005cf440fadb2c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3be2791b1d6c4854bc6371beaa74a5fa",
      "placeholder": "​",
      "style": "IPY_MODEL_cb6dfba869ef43c8ba3e70878ea4eb9b",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "e7708ac4f1d84c57b29d96cb403003e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efe1350ee5424d1e8a6f751111ca3a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0b2cd67041b4e2599c568150197b341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1ba71905be44aeca6f1332b98fdef21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27a017d1fc8e482096c39e9d61163ddc",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46c66efd3ff543abbbc00762ee5ea9ef",
      "value": 1355863
     }
    },
    "f3975a3e2aed471fb29c3a5ac33972bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8451def606f47d8a701247d6d0bca38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
