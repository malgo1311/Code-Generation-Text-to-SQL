{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9734110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOUNTING GOOGLE DRIVE\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "wd = '/content/drive/MyDrive/CS 685/cs685_project/notebooks'\n",
    "print(os.listdir(wd))\n",
    "os.chdir(wd)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c460be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tokenizers\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba03df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import trange\n",
    "import torch.optim as optim\n",
    "\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers.optimization import Adafactor\n",
    "from transformers.trainer_utils import set_seed\n",
    "# from utils.spider_metric.evaluator import EvaluateTool\n",
    "# from utils.load_dataset import Text2SQLDataset\n",
    "from load_dataset import Text2SQLDataset\n",
    "# from utils.text2sql_decoding_utils import decode_sqls, decode_natsqls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6862c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #'file path of test2sql training set.')\n",
    "# train_filepath = \"/Users/aishwarya/Downloads/spring23/cs685-NLP/project/spider/baselines/seq2seq_attention_copy/data/datasets/data_final/spider_combined_train.json\"\n",
    "# train_filepath = \"/Users/aishwarya/Downloads/spring23/cs685-NLP/project/data/resdsql_pre/preprocessed_dataset.json\" \n",
    "train_filepath = \"../data/resdsql_pre/preprocessed_dataset_train.json\"\n",
    "batch_size = 2 #'input batch size.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56791bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Text2SQLDataset(\n",
    "        dir_ = train_filepath,\n",
    "        mode = \"train\")\n",
    "\n",
    "train_dataloder = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = True,\n",
    "        collate_fn = lambda x: x,\n",
    "        drop_last = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd62ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloder:\n",
    "    batch_inputs = [data[0] for data in batch]\n",
    "    batch_sqls = [data[1] for data in batch]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050db96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs, batch_sqls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_len = 43\n",
    "max_decoder_len = 127\n",
    "\n",
    "# max_encoder_len += 2\n",
    "# max_decoder_len += 2\n",
    "\n",
    "gradient_descent_step = 4 #'perform gradient descent per \"gradient_descent_step\" steps.')\n",
    "# device = \"2\" #'the id of used GPU device.')\n",
    "learning_rate = 3e-5 #'learning rate.')\n",
    "epochs = 1 #'training epochs.')\n",
    "seed = 42 #'random seed.')\n",
    "save_path = \"models/text2sql\" #'save path of best fine-tuned text2sql model.')\n",
    "tensorboard_save_path= \"tb/text2sql\" #'save path of tensorboard log.')\n",
    "'''\n",
    "pre-trained model name. \n",
    "options: \n",
    "    t5-base, https://huggingface.co/t5-base;\n",
    "    t5-large, https://huggingface.co/t5-large;\n",
    "    t5-3b, https://huggingface.co/t5-3b;\n",
    ")'''\n",
    "\n",
    "model_name_or_path = \"t5-small\" #\"t5-3b\",\n",
    "use_adafactor = True #'whether to use adafactor optimizer.')\n",
    "mode = \"train\" #'trian, eval or test.')\n",
    "# dev_filepath = \"data/preprocessed_data/resdsql_dev.json\" #'file path of test2sql dev set.')\n",
    "# original_dev_filepath = \"data/spider/dev.json\" #'file path of the original dev set (for registing evaluator).')\n",
    "db_path = \"database\" #file path of database.')\n",
    "# tables_for_natsql = \"NatSQL/NatSQLv1_6/tables_for_natsql.json\" #'file path of tables_for_natsql.json.')\n",
    "num_beams = 8 #'beam size in model.generate() function.')\n",
    "num_return_sequences = 8 #'the number of returned sequences in model.generate() function (num_return_sequences <= num_beams).')\n",
    "\n",
    "output = \"predicted_sql.txt\" #\"save file of the predicted sqls.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f66c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "set_seed(seed)\n",
    "writer = SummaryWriter(tensorboard_save_path)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70154395",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2sql_tokenizer = T5TokenizerFast.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    add_prefix_space = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52323c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(text2sql_tokenizer, T5TokenizerFast):\n",
    "    text2sql_tokenizer.add_tokens([AddedToken(\" <=\"), AddedToken(\" <\")])\n",
    "\n",
    "train_dataset = Text2SQLDataset(\n",
    "    dir_ = train_filepath,\n",
    "    mode = \"train\")\n",
    "\n",
    "train_dataloder = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = True,\n",
    "    collate_fn = lambda x: x,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f52785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initializing text2sql model.\")\n",
    "# initialize model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "model.resize_token_embeddings(len(text2sql_tokenizer))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "print(\"finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0baa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warm up steps (10% training step)\n",
    "num_warmup_steps = int(0.1*epochs*len(train_dataset)/batch_size)\n",
    "# total training steps\n",
    "num_training_steps = int(epochs*len(train_dataset)/batch_size)\n",
    "# save checkpoint\n",
    "num_checkpoint_steps = 500\n",
    "\n",
    "print(\"Let's use Adafactor!\")\n",
    "optimizer = Adafactor(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate, \n",
    "    scale_parameter=False, \n",
    "    relative_step=False, \n",
    "    clip_threshold = 1.0,\n",
    "    warmup_init=False)\n",
    "\n",
    "#     print(\"Let's use AdamW!\")\n",
    "#     optimizer = optim.AdamW(\n",
    "#         model.parameters(), \n",
    "#         lr = learning_rate)\n",
    "\n",
    "scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = num_warmup_steps,\n",
    "    num_training_steps = num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60436a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "train_step = 0\n",
    "# initialize array of losses \n",
    "losses = {'train': {}, \"val\": {}}\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "with trange(epochs) as tr:\n",
    "    for epoch in tr:\n",
    "#         print(f\"This is epoch {epoch+1}.\")\n",
    "        batch_loss = 0\n",
    "    \n",
    "        for idx, batch in enumerate(train_dataloder):\n",
    "            train_step += 1\n",
    "\n",
    "            batch_inputs = [data[0] for data in batch]\n",
    "            batch_sqls = [data[1] for data in batch]\n",
    "    #             batch_db_ids = [data[2] for data in batch] # unused\n",
    "    #             batch_tc_original = [data[3] for data in batch] # unused\n",
    "\n",
    "    #         if epoch == 0 and idx == 0:\n",
    "    #             for batch_id in range(len(batch_inputs)):\n",
    "    #                 print(f\"batch_inputs - {batch_inputs[batch_id]}\")\n",
    "    #                 print(f\"batch_sqls - {batch_sqls[batch_id]}\")\n",
    "    # #                 print(\"----------------------\")\n",
    "\n",
    "            tokenized_inputs = text2sql_tokenizer(\n",
    "                batch_inputs, \n",
    "                padding = \"max_length\",\n",
    "                return_tensors = \"pt\",\n",
    "                max_length = max_encoder_len, #512,\n",
    "                truncation = True\n",
    "            )\n",
    "\n",
    "            with text2sql_tokenizer.as_target_tokenizer():\n",
    "                tokenized_outputs = text2sql_tokenizer(\n",
    "                    batch_sqls, \n",
    "                    padding = \"max_length\", \n",
    "                    return_tensors = 'pt',\n",
    "                    max_length = max_decoder_len, #256,\n",
    "                    truncation = True\n",
    "                )\n",
    "\n",
    "            encoder_input_ids = tokenized_inputs[\"input_ids\"]\n",
    "            encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"]\n",
    "\n",
    "            decoder_labels = tokenized_outputs[\"input_ids\"]\n",
    "            # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "            decoder_labels[decoder_labels == text2sql_tokenizer.pad_token_id] = -100\n",
    "            decoder_attention_mask = tokenized_outputs[\"attention_mask\"]\n",
    "\n",
    "    #         if idx == 0:\n",
    "    #             print(f\"tokenized_inputs - {tokenized_inputs}\")\n",
    "    #             print(f\"tokenized_outputs - {tokenized_outputs}\")\n",
    "    # #             print(f\"encoder_input_ids - {encoder_input_ids}\")\n",
    "    #             print(f\"encoder_input_attention_mask - {encoder_input_attention_mask}\")\n",
    "    #             print(f\"decoder_labels - {decoder_labels}\")\n",
    "    #             print(f\"decoder_attention_mask - {decoder_attention_mask}\")\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                encoder_input_ids = encoder_input_ids.cuda()\n",
    "                encoder_input_attention_mask = encoder_input_attention_mask.cuda()\n",
    "                decoder_labels = decoder_labels.cuda()\n",
    "                decoder_attention_mask = decoder_attention_mask.cuda()\n",
    "\n",
    "            model_outputs = model(\n",
    "                input_ids = encoder_input_ids,\n",
    "                attention_mask = encoder_input_attention_mask,\n",
    "                labels = decoder_labels,\n",
    "                decoder_attention_mask = decoder_attention_mask,\n",
    "                return_dict = True\n",
    "            )\n",
    "\n",
    "            loss = model_outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            \n",
    "            batch_loss += loss\n",
    "\n",
    "#             if scheduler is not None:\n",
    "#                 scheduler.step()\n",
    "\n",
    "            if writer is not None:\n",
    "                # record training loss (tensorboard)\n",
    "                writer.add_scalar('train loss', loss.item(), train_step)\n",
    "                # record learning rate (tensorboard)\n",
    "                writer.add_scalar('train lr', optimizer.state_dict()['param_groups'][0]['lr'], train_step)\n",
    "\n",
    "            if train_step % gradient_descent_step == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if train_step % num_checkpoint_steps == 0 and epoch >= 6:\n",
    "                print(f\"At {train_step} training step, save a checkpoint.\")\n",
    "                os.makedirs(save_path, exist_ok = True)\n",
    "                model.save_pretrained(save_directory = save_path + \"/checkpoint-{}\".format(train_step))\n",
    "                text2sql_tokenizer.save_pretrained(save_directory = save_path + \"/checkpoint-{}\".format(train_step))\n",
    "\n",
    "        batch_loss /= len(train_dataloder) \n",
    "        losses['train'][epoch] = f\"{batch_loss:.3f}\"\n",
    "        #progress bar \n",
    "        tr.set_postfix({\"epoch_num\":epoch,\n",
    "                        \"loss\":f\"{batch_loss:.10f}\"})\n",
    "    #         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_id in [42, 363, 1, 0, 58, 1738, 3,  9,  208,  122,   41, 4668,  834, 6254,  3,   61,   45, 6407]:\n",
    "    vocab_word = text2sql_tokenizer.convert_ids_to_tokens(token_id)\n",
    "    print(f\"{token_id} - {vocab_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22d4a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from text2sql_decoding_utils import decode_sqls\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "# from transformers.optimization import Adafactor\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "from load_dataset import Text2SQLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spider_metric.evaluator import EvaluateTool\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0399ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(mode,\n",
    "          dev_filepath,\n",
    "          original_dev_filepath,\n",
    "          save_path,\n",
    "          db_path,\n",
    "          batch_size,\n",
    "          num_beams, num_return_sequences,\n",
    "          output,\n",
    "          seed, device):\n",
    "    \n",
    "    set_seed(seed)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = device\n",
    "\n",
    "    # initialize tokenizer\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(\n",
    "        save_path,\n",
    "        add_prefix_space = True\n",
    "    )\n",
    "    \n",
    "    if isinstance(tokenizer, T5TokenizerFast):\n",
    "        tokenizer.add_tokens([AddedToken(\" <=\"), AddedToken(\" <\")])\n",
    "    \n",
    "    dev_dataset = Text2SQLDataset(\n",
    "        dir_ = dev_filepath,\n",
    "        mode = mode\n",
    "    )\n",
    "\n",
    "    dev_dataloder = DataLoader(\n",
    "        dev_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False,\n",
    "        collate_fn = lambda x: x,\n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "    # initialize model\n",
    "    model = T5ForConditionalGeneration.from_pretrained(save_path)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    predict_sqls = []\n",
    "    for batch in tqdm(dev_dataloder):\n",
    "        batch_inputs = [data[0] for data in batch]\n",
    "        batch_db_ids = [data[1] for data in batch]\n",
    "        batch_tc_original = [data[2] for data in batch]\n",
    "\n",
    "        tokenized_inputs = tokenizer(\n",
    "            batch_inputs, \n",
    "            return_tensors=\"pt\",\n",
    "            padding = \"max_length\",\n",
    "            max_length = 512,\n",
    "            truncation = True\n",
    "        )\n",
    "        \n",
    "        encoder_input_ids = tokenized_inputs[\"input_ids\"]\n",
    "        encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"]\n",
    "        if torch.cuda.is_available():\n",
    "            encoder_input_ids = encoder_input_ids.cuda()\n",
    "            encoder_input_attention_mask = encoder_input_attention_mask.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model.generate(\n",
    "                input_ids = encoder_input_ids,\n",
    "                attention_mask = encoder_input_attention_mask,\n",
    "                max_length = 256,\n",
    "                decoder_start_token_id = model.config.decoder_start_token_id,\n",
    "                num_beams = num_beams,\n",
    "                num_return_sequences = num_return_sequences\n",
    "            )\n",
    "\n",
    "            model_outputs = model_outputs.view(len(batch_inputs), num_return_sequences, model_outputs.shape[1])\n",
    "\n",
    "            predict_sqls += decode_sqls(\n",
    "                db_path, \n",
    "                model_outputs, \n",
    "                batch_db_ids, \n",
    "                batch_inputs, \n",
    "                tokenizer, \n",
    "                batch_tc_original\n",
    "            )\n",
    "            \n",
    "        break\n",
    "\n",
    "    new_dir = \"/\".join(output.split(\"/\")[:-1]).strip()\n",
    "    if new_dir != \"\":\n",
    "        os.makedirs(new_dir, exist_ok = True)\n",
    "    \n",
    "    # save results\n",
    "    with open(output, \"w\", encoding = 'utf-8') as f:\n",
    "        for pred in predict_sqls:\n",
    "            f.write(pred + \"\\n\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Text-to-SQL inference spends {}s.\".format(end_time-start_time))\n",
    "    \n",
    "    if mode == \"eval\":\n",
    "        # initialize evaluator\n",
    "        evaluator = EvaluateTool()\n",
    "        evaluator.register_golds(original_dev_filepath, db_path)\n",
    "        spider_metric_result = evaluator.evaluate(predict_sqls)\n",
    "        print('exact_match score: {}'.format(spider_metric_result[\"exact_match\"]))\n",
    "        print('exec score: {}'.format(spider_metric_result[\"exec\"]))\n",
    "    \n",
    "        return spider_metric_result[\"exact_match\"], spider_metric_result[\"exec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85188243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/696 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-SQL inference spends 1.879492998123169s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdev_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/resdsql_pre/preprocessed_dataset_test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_dev_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split/spider_test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../spider_data/database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/text2sql/checkpoint-6500\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted_sql.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 104\u001b[0m, in \u001b[0;36m_test\u001b[0;34m(mode, dev_filepath, original_dev_filepath, save_path, db_path, batch_size, num_beams, num_return_sequences, output, seed, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m EvaluateTool()\n\u001b[1;32m    103\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mregister_golds(original_dev_filepath, db_path)\n\u001b[0;32m--> 104\u001b[0m spider_metric_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_sqls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact_match score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/evaluator.py:60\u001b[0m, in \u001b[0;36mEvaluateTool.evaluate\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m     59\u001b[0m     exact_match \u001b[38;5;241m=\u001b[39m compute_exact_match_metric(preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgolds)\n\u001b[0;32m---> 60\u001b[0m     test_suite \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_test_suite_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexact_match, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtest_suite}\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/spider_test_suite.py:49\u001b[0m, in \u001b[0;36mcompute_test_suite_metric\u001b[0;34m(predictions, references, db_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdb_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturn_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturn_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected evaluation error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/evaluation.py:643\u001b[0m, in \u001b[0;36mEvaluator.evaluate_one\u001b[0;34m(self, db_name, gold, predicted, turn_scores, idx)\u001b[0m\n\u001b[1;32m    629\u001b[0m         p_sql \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_units\u001b[39m\u001b[38;5;124m\"\u001b[39m: []},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    640\u001b[0m         }\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 643\u001b[0m     exec_score \u001b[38;5;241m=\u001b[39m \u001b[43meval_exec_match\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplug_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplug_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_distinct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_distinct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exec_score:\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/exec_eval.py:240\u001b[0m, in \u001b[0;36meval_exec_match\u001b[0;34m(db, p_str, g_str, plug_value, keep_distinct, progress_bar_for_each_datapoint)\u001b[0m\n\u001b[1;32m    237\u001b[0m     ranger \u001b[38;5;241m=\u001b[39m db_paths\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m db_path \u001b[38;5;129;01min\u001b[39;00m ranger:\n\u001b[0;32m--> 240\u001b[0m     g_flag, g_denotation \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_on_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     p_flag, p_denotation \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(exec_on_db(db_path, pred))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# we should expect the gold to be succesfully executed on the database\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "_test(mode='eval',\n",
    "      dev_filepath=\"../data/resdsql_pre/preprocessed_dataset_test.json\",\n",
    "      original_dev_filepath=\"../data/split/spider_test.json\",\n",
    "      db_path = \"../spider_data/database\",\n",
    "      save_path=\"models/text2sql/checkpoint-6500\",\n",
    "      batch_size=1,\n",
    "      num_beams=2,\n",
    "      num_return_sequences=2,\n",
    "      output = \"predicted_sql.txt\",\n",
    "      seed=42,\n",
    "      device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ddd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f624416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
