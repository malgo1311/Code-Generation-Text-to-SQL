{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc49d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22434,
     "status": "ok",
     "timestamp": 1683756039554,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "44dc49d1",
    "outputId": "f71e642f-cc11-4720-847d-9983cfafdaad"
   },
   "outputs": [],
   "source": [
    "# # MOUNTING GOOGLE DRIVE\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "\n",
    "# wd = '/content/drive/MyDrive/CS 685/cs685_project/notebooks'\n",
    "# print(os.listdir(wd))\n",
    "# os.chdir(wd)\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EOrjkzvAqCng",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28261,
     "status": "ok",
     "timestamp": 1683756067809,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "EOrjkzvAqCng",
    "outputId": "a12095b7-7146-43c2-e55b-2153180dfe64",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tokenizers\n",
    "# !pip install transformers\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9ce01e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13533,
     "status": "ok",
     "timestamp": 1683756081335,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "ee9ce01e",
    "outputId": "754fbbbc-1c71-4490-81a9-e08292caace6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "from load_dataset import Text2SQLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tokenizers import AddedToken\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7334e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration = GPT2Config()\n",
    "# configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc843bcd",
   "metadata": {
    "id": "bc843bcd"
   },
   "source": [
    "## GPT2 + T5 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17abad9d",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683756081335,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "17abad9d"
   },
   "outputs": [],
   "source": [
    "# FOR PRINTING INTERMEDIATE TORCH SIZES\n",
    "DEBUG_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4921e160",
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1683756383738,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "4921e160"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, gpt2_hidden_size, t5_hidden_size, max_input_length, \n",
    "                 max_output_length, gpt2_model, t5_model, batch_size, gpt2_tokenizer):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "        self.t5_hidden_size = t5_hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.gpt2 = GPT2Model.from_pretrained(gpt2_model)\n",
    "        self.gpt2.resize_token_embeddings(len(gpt2_tokenizer))\n",
    "        \n",
    "        self.t5 = T5ForConditionalGeneration.from_pretrained(t5_model)\n",
    "        self.linear = nn.Linear(gpt2_hidden_size, t5_hidden_size)\n",
    "    \n",
    "        self.t5.config.is_encoder_decoder = False\n",
    "    \n",
    "\n",
    "    def forward(self, input_ids, input_mask,\n",
    "                decoder_input_ids, decoder_attention_mask):\n",
    "        \n",
    "        # Encode input with GPT2\n",
    "        gpt2_output = self.gpt2(input_ids=input_ids, attention_mask=input_mask)\n",
    "        gpt2_output = gpt2_output.last_hidden_state\n",
    "        \n",
    "        if DEBUG_FLAG: print(f\"gpt2_output - {gpt2_output.size()}\")\n",
    "        \n",
    "        # Transform GPT2 output to T5 input shape\n",
    "        t5_input = self.linear(gpt2_output)\n",
    "        if DEBUG_FLAG: print(f\"gpt2_output linear - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_input = t5_input.unsqueeze(1).repeat(1, self.max_output_length, 1)\n",
    "#         if DEBUG_FLAG: print(f\"gpt2_output linear unsqueeze - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_input = t5_input.view(self.batch_size, self.max_input_length, self.t5_hidden_size)\n",
    "        t5_input = t5_input.unsqueeze(0)\n",
    "        if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()}\")\n",
    "        \n",
    "#         t5_outputs = self.t5(decoder_input_ids=decoder_input_ids,\n",
    "#                              decoder_attention_mask=decoder_attention_mask,\n",
    "#                              encoder_outputs=t5_input\n",
    "#                             )\n",
    "#         if DEBUG_FLAG: print(f\"t5_input logits - {(t5_outputs.logits).size()}\")\n",
    "#         return t5_outputs.logits\n",
    "    \n",
    "        t5_outputs = self.t5(labels=decoder_input_ids,\n",
    "                             decoder_attention_mask=decoder_attention_mask,\n",
    "                             encoder_outputs=t5_input,\n",
    "                             return_dict = True\n",
    "                            )\n",
    "        \n",
    "        if DEBUG_FLAG: print(f\"t5_input - {type(t5_outputs)}\")\n",
    "        return t5_outputs\n",
    "\n",
    "    def predict(self, input_ids, input_mask, batch_size, t5_tokenizer):\n",
    "        \n",
    "        self.gpt2.eval()\n",
    "        # Encode input with GPT2\n",
    "        gpt2_output = self.gpt2(input_ids=input_ids, attention_mask=input_mask)\n",
    "        gpt2_output = gpt2_output.last_hidden_state\n",
    "        if DEBUG_FLAG: print(f\"gpt2_output - {gpt2_output.size()}\")\n",
    "        \n",
    "        # Transform BERT output to T5 input shape\n",
    "        t5_input = self.linear(gpt2_output)\n",
    "        if DEBUG_FLAG: print(f\"gpt2_output linear - {t5_input.size()}\")\n",
    "            \n",
    "#         t5_input = t5_input.view(batch_size, self.max_input_length, self.t5_hidden_size)\n",
    "        t5_input = t5_input.unsqueeze(0)\n",
    "        if DEBUG_FLAG: print(f\"t5_input - {t5_input.size()} - {t5_input}\")\n",
    "        \n",
    "        # Generate initial input for T5 decoder\n",
    "        start_token = t5_tokenizer.pad_token_id\n",
    "        \n",
    "#         decoder_input_ids = torch.tensor([start_token] * batch_size).unsqueeze(0)\n",
    "#         decoder_attention_mask = torch.tensor([1] * batch_size).unsqueeze(0)\n",
    "        \n",
    "        decoder_input_ids = torch.tensor([start_token]*batch_size).unsqueeze(0)\n",
    "        decoder_attention_mask = torch.tensor([1]*batch_size).unsqueeze(0)\n",
    "    \n",
    "#         decoder_input_ids = decoder_input_ids.view(decoder_input_ids.shape[1],\n",
    "#                                                    decoder_input_ids.shape[0])\n",
    "#         decoder_attention_mask = decoder_attention_mask.view(decoder_attention_mask.shape[1],\n",
    "#                                                              decoder_attention_mask.shape[0])\n",
    "        \n",
    "        print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "        print(f\"decoder_attention_mask - {decoder_attention_mask.size()}\")\n",
    "        \n",
    "        print(f\"initial decoder_input_ids - {decoder_input_ids}\")\n",
    "        \n",
    "        # Use the model to get output logits\n",
    "        # Predict the output\n",
    "        self.t5.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(50):  # Maximum length of generated sequence\n",
    "                t5_outputs = self.t5(decoder_input_ids=decoder_input_ids,\n",
    "                                     decoder_attention_mask=decoder_attention_mask,\n",
    "                                     encoder_outputs=t5_input)\n",
    "#                 print(f\"t5_outputs - {t5_outputs}\")\n",
    "                print(f\"t5_outputs logits - {(t5_outputs.logits).size()}\")\n",
    "    \n",
    "                next_token_logits = t5_outputs.logits[:, -1, :]\n",
    "                print(f\"next_token_logits - {next_token_logits.size()}\")\n",
    "            \n",
    "#                 next_token_id = torch.argmax(next_token_logits, dim=-1)\n",
    "                next_token_id = next_token_logits.argmax(1)\n",
    "#                 print(f\"next_token_id - {next_token_id.size()}\")\n",
    "#                 print(f\"next_token_id.unsqueeze(-1) - {next_token_id.unsqueeze(-1).size()}\")\n",
    "                decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(-1)], dim=-1)\n",
    "                decoder_attention_mask = torch.cat([decoder_attention_mask,\n",
    "                                                    torch.ones_like(next_token_id.unsqueeze(-1))], dim=-1)\n",
    "\n",
    "                if next_token_id == t5_tokenizer.eos_token_id:\n",
    "                    break\n",
    "                \n",
    "                print(f\"pred decoder_input_ids - {decoder_input_ids}\")\n",
    "                \n",
    "#                 break\n",
    "        \n",
    "        # generated_text\n",
    "#         t5_outputs = t5_tokenizer.decode(decoder_input_ids.squeeze(), skip_special_tokens=True)\n",
    "        t5_outputs = decoder_input_ids #.squeeze()\n",
    "        \n",
    "        return t5_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebafc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e519d2d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1683756664817,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "e519d2d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(train_filepath, batch_size, gpt2_hidden_size, t5_hidden_size, lr, num_epochs,\n",
    "         max_input_length, max_output_length, gpt2_model, t5_model):\n",
    "    \n",
    "    sub_folder_name = f\"GPT2_T5_lr{lr}_bs{batch_size}_{gpt2_model}_{t5_model}\"\n",
    "    models_directory = f\"models/{sub_folder_name}\"\n",
    "\n",
    "    if not os.path.isdir(models_directory):\n",
    "        os.makedirs(models_directory)\n",
    "        \n",
    "    # TENSORBOARD\n",
    "    writer = SummaryWriter(f'tb/loss_plot/{sub_folder_name}')\n",
    "    \n",
    "    train_dataset = Text2SQLDataset(\n",
    "            dir_ = train_filepath,\n",
    "            mode = \"train\")\n",
    "\n",
    "    train_dataloder = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size = batch_size, \n",
    "            shuffle = True,\n",
    "            collate_fn = lambda x: x,\n",
    "            drop_last = True\n",
    "        )\n",
    "    \n",
    "    print(f\"Number of batches - {len(train_dataloder)}\")\n",
    "\n",
    "    # Define GPT2 and T5 tokenizers\n",
    "    gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "    print(f\"Tokenizers loaded\")\n",
    "    \n",
    "    gpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "    model = EncoderDecoder(gpt2_hidden_size, t5_hidden_size, \n",
    "                           max_input_length, max_output_length,\n",
    "                           gpt2_model, t5_model, batch_size, gpt2_tokenizer).to(device)\n",
    "    print(f\"Model loaded\")\n",
    "#     print(f\"{model.config.decoder_start_token_id}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    print(f\"Otimizer - Adam\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=t5_tokenizer.pad_token_id)\n",
    "    print(f\"CrossEntropyLoss initialized\")\n",
    "    \n",
    "#     criterion = ContrastiveLoss()\n",
    "    \n",
    "    # initialize array of losses \n",
    "    losses = {'train': {}, \"val\": {}}\n",
    "\n",
    "    # for epoch in range(num_epochs):\n",
    "    with trange(num_epochs) as tr:\n",
    "        for epoch in tr:\n",
    "            \n",
    "            # Train the model\n",
    "            model.train()\n",
    "            \n",
    "            batch_loss = 0\n",
    "            \n",
    "            for idx, batch in enumerate(train_dataloder):\n",
    "\n",
    "                batch_inputs = [data[0] for data in batch]\n",
    "                batch_sqls = [data[1] for data in batch]\n",
    "\n",
    "                if DEBUG_FLAG:\n",
    "                    if epoch == 0 and idx == 0:\n",
    "                        print(f\"batch_inputs - {type(batch_inputs)} {len(batch_inputs)}\")\n",
    "                        print(f\"batch_sqls - {type(batch_sqls)} {len(batch_sqls)}\")\n",
    "                        \n",
    "#                 for temp_i, temp in enumerate(batch_inputs):\n",
    "#                     print(f\"batch_inputs - {batch_inputs[temp_i]}\")\n",
    "#                     print(f\"batch_sqls - {batch_sqls[temp_i]}\")\n",
    "\n",
    "                tokenized_inputs = gpt2_tokenizer(batch_inputs,\n",
    "                                                  add_special_tokens=True,\n",
    "                                                  padding=\"max_length\", #True,\n",
    "                                                  max_length=max_input_length,\n",
    "                                                  #pad_to_max_length=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True)\n",
    "\n",
    "                encoder_input_ids = tokenized_inputs[\"input_ids\"].to(device)\n",
    "                encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "#                 print(f\"encoder_input_ids - {encoder_input_ids}\")\n",
    "                tokenized_outputs = t5_tokenizer(batch_sqls,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 padding=\"max_length\", #True,\n",
    "                                                 max_length=max_output_length,\n",
    "                                                 #pad_to_max_length=True,\n",
    "                                                 return_tensors='pt',\n",
    "                                                 truncation=True)\n",
    "\n",
    "\n",
    "                decoder_input_ids = tokenized_outputs[\"input_ids\"].to(device)\n",
    "                # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "                decoder_input_ids[decoder_input_ids == t5_tokenizer.pad_token_id] = -100\n",
    "                decoder_attention_mask = tokenized_outputs[\"attention_mask\"].to(device)\n",
    "#                 labels = None #tokenized_outputs[\"attention_mask\"].to(device)\n",
    "\n",
    "#                 print(f\"decoder_input_ids - {decoder_input_ids}\")\n",
    "\n",
    "                if DEBUG_FLAG and epoch == 0 and idx == 0:\n",
    "                    print(f\"encoder_input_ids - {encoder_input_ids.size()}\")\n",
    "                    print(f\"encoder_input_attention_mask - {encoder_input_attention_mask.size()}\")\n",
    "                    print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "                    print(f\"decoder_attention_mask - {decoder_attention_mask.size()}\")\n",
    "\n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                model_output = model(encoder_input_ids,\n",
    "                               encoder_input_attention_mask,\n",
    "                               decoder_input_ids,\n",
    "                               decoder_attention_mask)\n",
    "#                                labels=labels)\n",
    "                \n",
    "                output = model_output[\"logits\"]\n",
    "#                 print(f\"output - {output.size()}\")\n",
    "#                 print(f\"decoder_input_ids - {decoder_input_ids.size()}\")\n",
    "                \n",
    "                output_resize = output.view(output.shape[0]*output.shape[1], output.shape[2])\n",
    "                decoder_input_ids_resize = decoder_input_ids.view(decoder_input_ids.shape[0]*decoder_input_ids.shape[1])\n",
    "                \n",
    "                print(f\"output_resize - {output_resize.size()}\")\n",
    "                print(f\"decoder_input_ids_resize - {decoder_input_ids_resize.size()}\")\n",
    "                    \n",
    "#                 loss = criterion(output_resize, decoder_input_ids_resize)\n",
    "#                 batch_loss += loss.item()\n",
    "                \n",
    "#                 print(f\"output - {model_output}\")\n",
    "                loss = model_output[\"loss\"]\n",
    "                batch_loss += loss\n",
    "                \n",
    "                predicted_classes = torch.argmax(output_resize, dim=-1)\n",
    "                print(f\"output_resize - {predicted_classes.size} - {predicted_classes}\")\n",
    "                \n",
    "#                 print(f\"decoder_input_ids_resize - {decoder_input_ids_resize}\")\n",
    "\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                break\n",
    "                \n",
    "            batch_loss /= len(train_dataloder) \n",
    "            losses['train'][epoch] = f\"{batch_loss:.3f}\"\n",
    "            #progress bar \n",
    "            tr.set_postfix({\"epoch_num\":epoch,\n",
    "                            \"loss\":f\"{batch_loss:.10f}\"})\n",
    "            \n",
    "#             with open(os.path.join(models_directory, \"loss.json\"), 'w') as f:\n",
    "#                 json.dump(losses, f)\n",
    "            \n",
    "#             writer.add_scalar('Training loss', batch_loss, global_step=epoch+1)\n",
    "#             # save models\n",
    "#             if (epoch > 3 and epoch % 5 == 0):\n",
    "#                 torch.save(model, os.path.join(models_directory, f\"model_{epoch}\"))\n",
    "#     torch.save(model, os.path.join(models_directory, f\"model_last_{epoch}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4444e046",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420541,
     "status": "ok",
     "timestamp": 1683757085355,
     "user": {
      "displayName": "Aishwarya Malgonde",
      "userId": "02733017902828562032"
     },
     "user_tz": 240
    },
    "id": "4444e046",
    "outputId": "279d8873-1753-4cf1-9622-eaab0b82a39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - 3152\n",
      "Tokenizers loaded\n",
      "Model loaded\n",
      "Otimizer - Adam\n",
      "CrossEntropyLoss initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_resize - torch.Size([254, 32128])\n",
      "decoder_input_ids_resize - torch.Size([254])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it, epoch_num=0, loss=0.0042370888]\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "train(train_filepath = \"../data/resdsql_pre/preprocessed_dataset_train.json\",\n",
    "      batch_size = 2, #32\n",
    "      gpt2_hidden_size = 768,\n",
    "      t5_hidden_size = 512,\n",
    "      lr = 1e-4,\n",
    "      num_epochs = 1, #300\n",
    "      max_input_length = 43,\n",
    "      max_output_length = 127,\n",
    "      gpt2_model = 'gpt2',\n",
    "      t5_model = 't5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa55e8",
   "metadata": {
    "id": "bbaa55e8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e5efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21797c26",
   "metadata": {
    "id": "083df0db"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b6b910f",
   "metadata": {
    "id": "6b6b910f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (gpt2): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (t5): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 8)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-5): 5 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "\n",
    "model_folder = \"models/GPT2_T5_lr0.0001_bs32_gpt2_t5-small/\"\n",
    "model_name = \"model_45\"\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), model_folder, model_name)\n",
    "output = os.path.join(os.getcwd(), model_folder, f\"{model_name}.txt\")\n",
    "\n",
    "model2 = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "353361ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "from text2sql_decoding_utils import decode_sqls\n",
    "from spider_metric.evaluator import EvaluateTool\n",
    "\n",
    "dev_filepath = \"../data/resdsql_pre/preprocessed_dataset_test.json\"\n",
    "original_dev_filepath = \"../data/split/spider_test.json\"\n",
    "\n",
    "batch_size = 1\n",
    "max_input_length = 43\n",
    "gpt2_model = 'gpt2'\n",
    "t5_model = 't5-small'\n",
    "db_path = \"../spider_data/database\"\n",
    "mode = \"eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c38bf753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_ids - torch.Size([1, 43])\n",
      "encoder_input_attention_mask - torch.Size([1, 43])\n",
      "gpt2_output - torch.Size([1, 43, 768])\n",
      "gpt2_output linear - torch.Size([1, 43, 512])\n",
      "t5_input - torch.Size([1, 1, 43, 512]) - tensor([[[[-0.0062,  0.0012,  0.1066,  ...,  0.0302,  0.1079, -0.1081],\n",
      "          [-0.0788, -0.0619, -0.1048,  ...,  0.0212,  0.1037, -0.1099],\n",
      "          [-0.0513,  0.1958,  0.0470,  ...,  0.0699,  0.2082,  0.2164],\n",
      "          ...,\n",
      "          [ 0.0589,  0.1992, -0.0373,  ...,  0.0252,  0.1220, -0.0641],\n",
      "          [ 0.0616,  0.1989, -0.0402,  ...,  0.0280,  0.1228, -0.0624],\n",
      "          [ 0.0636,  0.1986, -0.0399,  ...,  0.0273,  0.1219, -0.0626]]]])\n",
      "decoder_input_ids - torch.Size([1, 1])\n",
      "decoder_attention_mask - torch.Size([1, 1])\n",
      "initial decoder_input_ids - tensor([[0]])\n",
      "t5_outputs logits - torch.Size([1, 1, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738]])\n",
      "t5_outputs logits - torch.Size([1, 2, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476]])\n",
      "t5_outputs logits - torch.Size([1, 3, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41]])\n",
      "t5_outputs logits - torch.Size([1, 4, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429]])\n",
      "t5_outputs logits - torch.Size([1, 5, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3]])\n",
      "t5_outputs logits - torch.Size([1, 6, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61]])\n",
      "t5_outputs logits - torch.Size([1, 7, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3]])\n",
      "t5_outputs logits - torch.Size([1, 8, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6]])\n",
      "t5_outputs logits - torch.Size([1, 9, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6, 2259]])\n",
      "t5_outputs logits - torch.Size([1, 10, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6, 2259,  834]])\n",
      "t5_outputs logits - torch.Size([1, 11, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6, 2259,  834, 4350]])\n",
      "t5_outputs logits - torch.Size([1, 12, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6, 2259,  834, 4350,\n",
      "           45]])\n",
      "t5_outputs logits - torch.Size([1, 13, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "pred decoder_input_ids - tensor([[   0, 1738, 3476,   41, 1429,    3,   61,    3,    6, 2259,  834, 4350,\n",
      "           45, 2259]])\n",
      "t5_outputs logits - torch.Size([1, 14, 32128])\n",
      "next_token_logits - torch.Size([1, 32128])\n",
      "select count ( * ) , competition_name from competition\n",
      "no such table: competition\n",
      "Text-to-SQL inference spends 1.2708361148834229s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m EvaluateTool()\n\u001b[1;32m     80\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mregister_golds(original_dev_filepath, db_path)\n\u001b[0;32m---> 81\u001b[0m spider_metric_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_sqls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact_match score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/evaluator.py:60\u001b[0m, in \u001b[0;36mEvaluateTool.evaluate\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m     59\u001b[0m     exact_match \u001b[38;5;241m=\u001b[39m compute_exact_match_metric(preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgolds)\n\u001b[0;32m---> 60\u001b[0m     test_suite \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_test_suite_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexact_match, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtest_suite}\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/spider_test_suite.py:49\u001b[0m, in \u001b[0;36mcompute_test_suite_metric\u001b[0;34m(predictions, references, db_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdb_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturn_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturn_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected evaluation error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/evaluation.py:643\u001b[0m, in \u001b[0;36mEvaluator.evaluate_one\u001b[0;34m(self, db_name, gold, predicted, turn_scores, idx)\u001b[0m\n\u001b[1;32m    629\u001b[0m         p_sql \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_units\u001b[39m\u001b[38;5;124m\"\u001b[39m: []},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    640\u001b[0m         }\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 643\u001b[0m     exec_score \u001b[38;5;241m=\u001b[39m \u001b[43meval_exec_match\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplug_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplug_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_distinct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_distinct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exec_score:\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/exec_eval.py:240\u001b[0m, in \u001b[0;36meval_exec_match\u001b[0;34m(db, p_str, g_str, plug_value, keep_distinct, progress_bar_for_each_datapoint)\u001b[0m\n\u001b[1;32m    237\u001b[0m     ranger \u001b[38;5;241m=\u001b[39m db_paths\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m db_path \u001b[38;5;129;01min\u001b[39;00m ranger:\n\u001b[0;32m--> 240\u001b[0m     g_flag, g_denotation \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_on_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     p_flag, p_denotation \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(exec_on_db(db_path, pred))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# we should expect the gold to be succesfully executed on the database\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# initialize tokenizer\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "\n",
    "gpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# if isinstance(tokenizer, T5TokenizerFast):\n",
    "#     tokenizer.add_tokens([AddedToken(\" <=\"), AddedToken(\" <\")])\n",
    "\n",
    "dev_dataset = Text2SQLDataset(\n",
    "            dir_ = dev_filepath,\n",
    "            mode = mode)\n",
    "\n",
    "dev_dataloder = DataLoader(\n",
    "        dev_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False,\n",
    "        collate_fn = lambda x: x,\n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "# initialize model\n",
    "\n",
    "model2.eval()\n",
    "predict_sqls = []\n",
    "# for batch in tqdm(dev_dataloder):\n",
    "for idx, batch in enumerate(dev_dataloder):\n",
    "    batch_inputs = [data[0] for data in batch]\n",
    "    batch_db_ids = [data[1] for data in batch]\n",
    "    batch_tc_original = [data[2] for data in batch]\n",
    "\n",
    "    tokenized_inputs = gpt2_tokenizer(batch_inputs,\n",
    "                                      add_special_tokens=True,\n",
    "                                      padding=\"max_length\", #True,\n",
    "                                      max_length=max_input_length,\n",
    "                                      #pad_to_max_length=True,\n",
    "                                      return_tensors='pt',\n",
    "                                      truncation=True)\n",
    "\n",
    "    encoder_input_ids = tokenized_inputs[\"input_ids\"].to(device)\n",
    "    encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    print(f\"encoder_input_ids - {encoder_input_ids.size()}\")\n",
    "    print(f\"encoder_input_attention_mask - {encoder_input_attention_mask.size()}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_outputs = model2.predict(encoder_input_ids, encoder_input_attention_mask,\n",
    "                                       batch_size, t5_tokenizer=t5_tokenizer)\n",
    "\n",
    "        model_outputs = model_outputs.view(batch_size, 1, model_outputs.shape[1])\n",
    "        \n",
    "        predict_sqls += decode_sqls(\n",
    "                                    db_path, \n",
    "                                    model_outputs, \n",
    "                                    batch_db_ids, \n",
    "                                    batch_inputs, \n",
    "                                    t5_tokenizer, \n",
    "                                    batch_tc_original\n",
    "                                    )\n",
    "    break\n",
    "\n",
    "\n",
    "new_dir = \"/\".join(output.split(\"/\")[:-1]).strip()\n",
    "if new_dir != \"\":\n",
    "    os.makedirs(new_dir, exist_ok = True)\n",
    "\n",
    "# save results\n",
    "with open(output, \"w\", encoding = 'utf-8') as f:\n",
    "    for pred in predict_sqls:\n",
    "        f.write(pred + \"\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Text-to-SQL inference spends {}s.\".format(end_time-start_time))\n",
    "\n",
    "if mode == \"eval\":\n",
    "    # initialize evaluator\n",
    "    evaluator = EvaluateTool()\n",
    "    evaluator.register_golds(original_dev_filepath, db_path)\n",
    "    spider_metric_result = evaluator.evaluate(predict_sqls)\n",
    "    print('exact_match score: {}'.format(spider_metric_result[\"exact_match\"]))\n",
    "    print('exec score: {}'.format(spider_metric_result[\"exec\"]))\n",
    "    \n",
    "    em_res = spider_metric_result[\"exact_match\"]\n",
    "    ex_res = spider_metric_result[\"exec\"]\n",
    "#     return spider_metric_result[\"exact_match\"], spider_metric_result[\"exec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs, model_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf57136",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs, batch_db_ids, batch_tc_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b5b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
