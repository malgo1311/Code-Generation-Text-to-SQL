{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-C-jcdTIrNv",
    "outputId": "10c2b477-511b-4652-92f9-81deffa4782a"
   },
   "outputs": [],
   "source": [
    "# # MOUNTING GOOGLE DRIVE\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DFYovmq0I3-Z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuGRKc02KS4Q"
   },
   "source": [
    "## Check spider data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua7iv3Y8I8Kh",
    "outputId": "66c5fa52-68e5-45a8-d42c-dd62268ec49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dev_gold.sql', 'database', '.DS_Store', 'train_others.json', 'train_spider.json', 'tables.json', 'dev.json', 'README.txt', 'train_gold.sql']\n"
     ]
    }
   ],
   "source": [
    "# data_path = '/content/drive/MyDrive/CS 685/cs685_project/spider_data'\n",
    "data_path = '/Users/aishwarya/Downloads/spring23/cs685-NLP/project/spider_data'\n",
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_lZKu29I1E8",
    "outputId": "cd1117d9-6515-4758-d288-a38b2c621f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File - train_spider.json; length - 7000\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "db_id \t\t - department_management\n",
      "query \t\t - SELECT count(*) FROM head WHERE age  >  56\n",
      "query_toks \t\t - ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56']\n",
      "query_toks_no_value \t\t - ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value']\n",
      "question \t\t - How many heads of the departments are older than 56 ?\n",
      "question_toks \t\t - ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?']\n",
      "sql \t\t - {'except': None, 'from': {'conds': [], 'table_units': [['table_unit', 1]]}, 'groupBy': [], 'having': [], 'intersect': None, 'limit': None, 'orderBy': [], 'select': [False, [[3, [0, [0, 0, False], None]]]], 'union': None, 'where': [[False, 3, [0, [0, 10, False], None], 56.0, None]]}\n",
      "\n",
      "##############################\n",
      "\n",
      "File - train_others.json; length - 1659\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "db_id \t\t - geo\n",
      "query \t\t - SELECT city_name FROM city WHERE population  =  ( SELECT MAX ( population ) FROM city WHERE state_name  =  \"wyoming\" ) AND state_name  =  \"wyoming\";\n",
      "query_toks \t\t - ['SELECT', 'city_name', 'FROM', 'city', 'WHERE', 'population', '=', '(', 'SELECT', 'MAX', '(', 'population', ')', 'FROM', 'city', 'WHERE', 'state_name', '=', '``', 'wyoming', \"''\", ')', 'AND', 'state_name', '=', '``', 'wyoming', \"''\", ';']\n",
      "query_toks_no_value \t\t - ['select', 'city_name', 'from', 'city', 'where', 'population', '=', '(', 'select', 'max', '(', 'population', ')', 'from', 'city', 'where', 'state_name', '=', 'value', ')', 'and', 'state_name', '=', 'value']\n",
      "question \t\t - what is the biggest city in wyoming\n",
      "question_toks \t\t - ['what', 'is', 'the', 'biggest', 'city', 'in', 'wyoming']\n",
      "sql \t\t - {'except': None, 'from': {'conds': [], 'table_units': [['table_unit', 1]]}, 'groupBy': [], 'having': [], 'intersect': None, 'limit': None, 'orderBy': [], 'select': [False, [[0, [0, [0, 7, False], None]]]], 'union': None, 'where': [[False, 2, [0, [0, 8, False], None], {'except': None, 'from': {'conds': [], 'table_units': [['table_unit', 1]]}, 'groupBy': [], 'having': [], 'intersect': None, 'limit': None, 'orderBy': [], 'select': [False, [[1, [0, [0, 8, False], None]]]], 'union': None, 'where': [[False, 2, [0, [0, 10, False], None], '\"wyoming\"', None]]}, None], 'and', [False, 2, [0, [0, 10, False], None], '\"wyoming\"', None]]}\n",
      "\n",
      "##############################\n",
      "\n",
      "File - dev.json; length - 1034\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "db_id \t\t - concert_singer\n",
      "query \t\t - SELECT count(*) FROM singer\n",
      "query_toks \t\t - ['SELECT', 'count', '(', '*', ')', 'FROM', 'singer']\n",
      "query_toks_no_value \t\t - ['select', 'count', '(', '*', ')', 'from', 'singer']\n",
      "question \t\t - How many singers do we have?\n",
      "question_toks \t\t - ['How', 'many', 'singers', 'do', 'we', 'have', '?']\n",
      "sql \t\t - {'except': None, 'from': {'conds': [], 'table_units': [['table_unit', 1]]}, 'groupBy': [], 'having': [], 'intersect': None, 'limit': None, 'orderBy': [], 'select': [False, [[3, [0, [0, 0, False], None]]]], 'union': None, 'where': []}\n",
      "\n",
      "##############################\n",
      "\n",
      "File - tables.json; length - 166\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "column_names \t\t - [[-1, '*'], [0, 'perpetrator id'], [0, 'people id'], [0, 'date'], [0, 'year'], [0, 'location'], [0, 'country'], [0, 'killed'], [0, 'injured'], [1, 'people id'], [1, 'name'], [1, 'height'], [1, 'weight'], [1, 'home town']]\n",
      "column_names_original \t\t - [[-1, '*'], [0, 'Perpetrator_ID'], [0, 'People_ID'], [0, 'Date'], [0, 'Year'], [0, 'Location'], [0, 'Country'], [0, 'Killed'], [0, 'Injured'], [1, 'People_ID'], [1, 'Name'], [1, 'Height'], [1, 'Weight'], [1, 'Home Town']]\n",
      "column_types \t\t - ['text', 'number', 'number', 'text', 'number', 'text', 'text', 'number', 'number', 'number', 'text', 'number', 'number', 'text']\n",
      "db_id \t\t - perpetrator\n",
      "foreign_keys \t\t - [[2, 9]]\n",
      "primary_keys \t\t - [1, 9]\n",
      "table_names \t\t - ['perpetrator', 'people']\n",
      "table_names_original \t\t - ['perpetrator', 'people']\n",
      "\n",
      "##############################\n",
      "\n",
      "Number of tables in database - 167\n"
     ]
    }
   ],
   "source": [
    "for file in [\"train_spider.json\", \"train_others.json\", \"dev.json\", \"tables.json\"]:\n",
    "    with open(os.path.join(data_path, file)) as inf:\n",
    "        sql_data = json.load(inf)\n",
    "    print(f'File - {file}; length - {len(sql_data)}')\n",
    "\n",
    "    print('##############################')\n",
    "    print('Sample data')\n",
    "    print('##############################')\n",
    "    counter = 0\n",
    "    for item in sql_data:\n",
    "      for k, v in item.items():\n",
    "        print(f\"{k} \\t\\t - {v}\")\n",
    "\n",
    "      print()\n",
    "      counter += 1\n",
    "      if counter > 0: break\n",
    "    print('##############################')\n",
    "    print()\n",
    "\n",
    "\n",
    "folder = 'database'\n",
    "db_dir = os.path.join(data_path, folder)\n",
    "all_folders = os.listdir(db_dir)\n",
    "# all_folders.remove('.DS_Store')\n",
    "print(f'Number of tables in {folder} - {len(all_folders)}')\n",
    "# for i in sorted():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj2h-gsZJpiC",
    "outputId": "23f0eae8-90d9-4b8d-fbb1-ee10db3c3eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File - train_spider.json; length - 7000\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "##############################\n",
      "all_queries - 7000\n",
      "all_queries - 3964 - after removing duplicate\n",
      "\n",
      "{'SELECT': 3964, 'FROM': 3964, 'GROUP BY': 1011, 'count(': 1088, 'DESC': 502, 'LIMIT': 625, 'ORDER BY': 935, 'WHERE': 1941, '=': 2142, 'IN': 154, 'NOT IN': 128, 'JOIN': 1565, 'HAVING': 250, 'AS': 1548, 'AND': 308, 'DISTINCT': 246, 'OR': 126, '>': 410, 'avg(': 265, 'UNION': 35, '<': 161, 'max(': 134, 'min(': 93, 'MATCH': 11}\n",
      "\n",
      "File - train_others.json; length - 1659\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "##############################\n",
      "all_queries - 1659\n",
      "all_queries - 750 - after removing duplicate\n",
      "\n",
      "{'SELECT': 750, 'FROM': 750, 'WHERE': 707, 'JOIN': 482, 'AS': 482, 'DISTINCT': 295, '=': 698, 'DESC': 42, 'LIMIT': 45, 'ORDER BY': 86, 'AND': 296, 'IN': 67, 'GROUP BY': 99, 'HAVING': 20, '>': 106, '<': 21, 'NOT IN': 6}\n",
      "\n",
      "File - dev.json; length - 1034\n",
      "##############################\n",
      "Sample data\n",
      "##############################\n",
      "##############################\n",
      "all_queries - 1034\n",
      "all_queries - 546 - after removing duplicate\n",
      "\n",
      "{'SELECT': 546, 'FROM': 546, 'UNION': 7, 'WHERE': 264, 'JOIN': 216, 'AS': 218, '=': 304, 'GROUP BY': 143, 'DESC': 75, 'LIMIT': 100, 'ORDER BY': 126, 'HAVING': 41, 'count(': 182, 'avg(': 36, '>': 57, 'DISTINCT': 27, 'AND': 34, 'min(': 15, '<': 23, 'OR': 19, 'max(': 23, 'IN': 25, 'NOT IN': 23}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in [\"train_spider.json\", \"train_others.json\", \"dev.json\"]:\n",
    "# for file in [\"dev.json\"]:\n",
    "    with open(os.path.join(data_path, file)) as inf:\n",
    "        sql_data = json.load(inf)\n",
    "    print(f'File - {file}; length - {len(sql_data)}')\n",
    "\n",
    "    print('##############################')\n",
    "    print('Sample data')\n",
    "    print('##############################')\n",
    "    counter = 1\n",
    "    all_queries = []\n",
    "    for item in sql_data:\n",
    "        for k, v in item.items():          \n",
    "          if k == \"query\":  all_queries.append(v)\n",
    "\n",
    "    print('##############################')\n",
    "\n",
    "    print(f\"all_queries - {len(all_queries)}\")\n",
    "    all_queries = list(set(all_queries))\n",
    "    print(f\"all_queries - {len(all_queries)} - after removing duplicate\")\n",
    "\n",
    "    print()\n",
    "    counts = {}\n",
    "    check = ['SELECT ', ' FROM ', ' GROUP BY ', ' WHERE ', ' JOIN ', ' MATCH ',\n",
    "             ' DESC ', ' LIMIT ', ' ORDER BY ', ' HAVING ', ' AS ', ' UNION ',\n",
    "             ' OR ', ' AND ', ' IN ', ' NOT IN ', ' DISTINCT ', ' max(',\n",
    "             ' min(', ' avg(', ' count(', ' > ', ' < ', ' = ']\n",
    "    for idx, query in enumerate(all_queries):\n",
    "      # print(idx, query)\n",
    "      for item in check:\n",
    "        if item in query:\n",
    "          var_name = item.strip()\n",
    "          if var_name not in counts.keys():\n",
    "            counts[var_name] = 0\n",
    "          counts[var_name] += 1\n",
    "\n",
    "    print(counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zimm6i1k8gMY"
   },
   "source": [
    "## Splitting train_spider.json into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaLQJSSxLSX9"
   },
   "source": [
    "### Combine train_spider and train_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-Bp6KLNLRGq",
    "outputId": "721d5e7d-a7b3-4d62-c545-c0e412508ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File - train_spider.json; length - 7000\n",
      "combined length - 7000\n",
      "idx - 6300\n",
      "File - train; length - 6300\n",
      "File - test; length - 700\n"
     ]
    }
   ],
   "source": [
    "file = \"train_spider.json\"\n",
    "with open(os.path.join(data_path, file)) as inf:\n",
    "    train_spider = json.load(inf)\n",
    "print(f'File - {file}; length - {len(train_spider)}')\n",
    "\n",
    "train_others = []\n",
    "# file = \"train_others.json\"\n",
    "# with open(os.path.join(data_path, file)) as inf:\n",
    "#     train_others = json.load(inf)\n",
    "# print(f'File - {file}; length - {len(train_others)}')\n",
    "\n",
    "combined = train_spider + train_others\n",
    "print(f'combined length - {len(combined)}')\n",
    "\n",
    "train_size = 0.9\n",
    "idx = int(len(combined)*train_size)\n",
    "print(f'idx - {idx}')\n",
    "\n",
    "train = combined[:idx]\n",
    "test = combined[idx:]\n",
    "\n",
    "print(f'File - train; length - {len(train)}')\n",
    "print(f'File - test; length - {len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbGfBCZxMuXp"
   },
   "source": [
    "### Check for overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4unrLkfMuH-",
    "outputId": "ee19ad3d-a95b-40b5-f090-0dd2cfae3e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train queries - 6300\n",
      "train queries - 3577 - after removing duplicates\n",
      "test queries - 700\n",
      "test queries - 389 - after removing duplicates\n",
      "common queries - 2\n"
     ]
    }
   ],
   "source": [
    "train_queries = [item['query'] for item in train]\n",
    "\n",
    "print(f\"train queries - {len(train_queries)}\")\n",
    "train_queries_unq = list(set(train_queries))\n",
    "print(f\"train queries - {len(train_queries_unq)} - after removing duplicates\")\n",
    "\n",
    "test_queries = [item['query'] for item in test]\n",
    "\n",
    "print(f\"test queries - {len(test_queries)}\")\n",
    "test_queries_unq = list(set(test_queries))\n",
    "print(f\"test queries - {len(test_queries_unq)} - after removing duplicates\")\n",
    "\n",
    "common_qs = [q for q in test_queries if q in train_queries]\n",
    "common_qs = list(set(common_qs))\n",
    "print(f\"common queries - {len(common_qs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_InhmpxLQ9c",
    "outputId": "141d949b-bb29-43cc-cdec-6591783bc3c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_items = []\n",
    "for item1 in test:\n",
    "  for dup in common_qs:\n",
    "    if item1['query'] == dup:\n",
    "      remove_items.append(item1)\n",
    "  \n",
    "len(remove_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNyPJcWNLQyW",
    "outputId": "094aa696-832c-4f64-c1db-4f9d39940086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 696)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in remove_items:\n",
    "  test.remove(item)\n",
    "  train.append(item)\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2M-JoxQKJkh",
    "outputId": "df9dee29-cee5-4507-8efd-e86d4138424d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_queries - 6304\n",
      "all_queries - 3577 - after removing duplicate\n",
      "##############################\n",
      "all_queries - 696\n",
      "all_queries - 387 - after removing duplicate\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "for list_l in [train, test]:\n",
    "  all_queries = []\n",
    "  for item in list_l:\n",
    "      for k, v in item.items():          \n",
    "        if k == \"query\":  all_queries.append(v)\n",
    "\n",
    "  print(f\"all_queries - {len(all_queries)}\")\n",
    "  all_queries = list(set(all_queries))\n",
    "  print(f\"all_queries - {len(all_queries)} - after removing duplicate\")\n",
    "\n",
    "  print('##############################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5YZ77oSN9IUH"
   },
   "outputs": [],
   "source": [
    "data_path_target = \"/Users/aishwarya/Downloads/spring23/cs685-NLP/project/data/split\"\n",
    "\n",
    "if not os.path.isdir(data_path_target):\n",
    "    os.makedirs(data_path_target)\n",
    "\n",
    "# with open(os.path.join(data_path_target, \"spider_combined.json\"), 'wt') as out:\n",
    "#   json.dump(combined, out, sort_keys=True, indent=2, separators=(',', ': '))\n",
    "\n",
    "with open(os.path.join(data_path_target, \"spider_train.json\"), 'wt') as out:\n",
    "  json.dump(train, out, sort_keys=True, indent=2, separators=(',', ': '))\n",
    "\n",
    "with open(os.path.join(data_path_target, \"spider_test.json\"), 'wt') as out:\n",
    "  json.dump(test, out, sort_keys=True, indent=2, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2SmGzypJ2Fp"
   },
   "source": [
    "## Check for overlap in Train-Dev-Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUFspBXN9so0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
