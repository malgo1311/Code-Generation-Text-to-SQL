{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9e5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from tokenizers import AddedToken\n",
    "from utils.classifier_metric.evaluator import cls_metric, auc_metric\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizerFast\n",
    "from utils.classifier_model import MyClassifier\n",
    "from utils.classifier_loss import ClassifierLoss\n",
    "from transformers.trainer_utils import set_seed\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from load_dataset import ColumnAndTableClassifierDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e530e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seed = 42\n",
    "save_path = \"models/schema_item_classifier_v2_ep4/\"\n",
    "dev_filepath = \"../data/resdsql_pre/preprocessed_dataset_test.json\"\n",
    "use_contents=True\n",
    "add_fk_info=True\n",
    "mode = \"eval\" #'trian, eval or test.')\n",
    "\n",
    "# tensorboard_save_path = None,\n",
    "# train_filepath = \"../data/pre-processing/preprocessed_train_spider.json\",\n",
    "# output_filepath = \"../data/pre-processing/dataset_with_pred_probs.json\",\n",
    "# model_name_or_path = \"roberta-large\",\n",
    "# gradient_descent_step = 4\n",
    "# device = ''\n",
    "# learning_rate = 3e-5,\n",
    "# gamma = 1.0,\n",
    "# alpha = 1.0,\n",
    "# epochs = 128,\n",
    "# patience = 32,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81c7622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['added_tokens.json',\n",
       " 'tokenizer_config.json',\n",
       " 'special_tokens_map.json',\n",
       " 'config.json',\n",
       " 'tokenizer.json',\n",
       " 'tb',\n",
       " 'dense_classifier.pt',\n",
       " 'loss.json',\n",
       " 'merges.txt',\n",
       " 'vocab.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73623ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0065c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch_inputs_and_labels(batch, tokenizer):\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    batch_questions = [data[0] for data in batch]\n",
    "    \n",
    "    batch_table_names = [data[1] for data in batch]\n",
    "    batch_table_labels = [data[2] for data in batch]\n",
    "\n",
    "    batch_column_infos = [data[3] for data in batch]\n",
    "    batch_column_labels = [data[4] for data in batch]\n",
    "    \n",
    "    if DEBUG_FLAG: print(f\"batch_questions - {batch_questions}\")\n",
    "    if DEBUG_FLAG: print(f\"batch_table_names - {batch_table_names}\")\n",
    "    if DEBUG_FLAG: print(f\"batch_table_labels - {batch_table_labels}\")\n",
    "    if DEBUG_FLAG: print(f\"batch_column_infos - {batch_column_infos}\")\n",
    "    if DEBUG_FLAG: print(f\"batch_column_labels - {batch_column_labels}\")\n",
    "    \n",
    "    batch_input_tokens, batch_column_info_ids, batch_table_name_ids, batch_column_number_in_each_table = [], [], [], []\n",
    "    for batch_id in range(batch_size):\n",
    "        input_tokens = [batch_questions[batch_id]]\n",
    "        table_names_in_one_db = batch_table_names[batch_id]\n",
    "        column_infos_in_one_db = batch_column_infos[batch_id]\n",
    "\n",
    "        batch_column_number_in_each_table.append([len(column_infos_in_one_table) for column_infos_in_one_table in column_infos_in_one_db])\n",
    "\n",
    "        column_info_ids, table_name_ids = [], []\n",
    "        \n",
    "        for table_id, table_name in enumerate(table_names_in_one_db):\n",
    "            input_tokens.append(\"|\")\n",
    "            input_tokens.append(table_name)\n",
    "            table_name_ids.append(len(input_tokens) - 1)\n",
    "            input_tokens.append(\":\")\n",
    "            \n",
    "            for column_info in column_infos_in_one_db[table_id]:\n",
    "                input_tokens.append(column_info)\n",
    "                column_info_ids.append(len(input_tokens) - 1)\n",
    "                input_tokens.append(\",\")\n",
    "            \n",
    "            input_tokens = input_tokens[:-1]\n",
    "            \n",
    "        if DEBUG_FLAG and batch_id == 0: print(f\"input_tokens - {input_tokens}\")\n",
    "        \n",
    "        batch_input_tokens.append(input_tokens)\n",
    "        batch_column_info_ids.append(column_info_ids)\n",
    "        batch_table_name_ids.append(table_name_ids)\n",
    "\n",
    "    # notice: the trunction operation will discard some tables and columns that exceed the max length\n",
    "    tokenized_inputs = tokenizer(\n",
    "        batch_input_tokens, \n",
    "        return_tensors=\"pt\", \n",
    "        is_split_into_words = True, \n",
    "        padding = \"max_length\",\n",
    "        max_length = 512,\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    batch_aligned_question_ids, batch_aligned_column_info_ids, batch_aligned_table_name_ids = [], [], []\n",
    "    batch_aligned_table_labels, batch_aligned_column_labels = [], []\n",
    "    \n",
    "    # align batch_question_ids, batch_column_info_ids, and batch_table_name_ids after tokenizing\n",
    "    for batch_id in range(batch_size):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index = batch_id)\n",
    "\n",
    "        aligned_question_ids, aligned_table_name_ids, aligned_column_info_ids = [], [], []\n",
    "        aligned_table_labels, aligned_column_labels = [], []\n",
    "\n",
    "        # align question tokens\n",
    "        for token_id, word_id in enumerate(word_ids):\n",
    "            if word_id == 0:\n",
    "                aligned_question_ids.append(token_id)\n",
    "\n",
    "        # align table names\n",
    "        for t_id, table_name_id in enumerate(batch_table_name_ids[batch_id]):\n",
    "            temp_list = []\n",
    "            for token_id, word_id in enumerate(word_ids):\n",
    "                if table_name_id == word_id:\n",
    "                    temp_list.append(token_id)\n",
    "            # if the tokenizer doesn't discard current table name\n",
    "            if len(temp_list) != 0:\n",
    "                aligned_table_name_ids.append(temp_list)\n",
    "                aligned_table_labels.append(batch_table_labels[batch_id][t_id])\n",
    "\n",
    "        # align column names\n",
    "        for c_id, column_id in enumerate(batch_column_info_ids[batch_id]):\n",
    "            temp_list = []\n",
    "            for token_id, word_id in enumerate(word_ids):\n",
    "                if column_id == word_id:\n",
    "                    temp_list.append(token_id)\n",
    "            # if the tokenizer doesn't discard current column name\n",
    "            if len(temp_list) != 0:\n",
    "                aligned_column_info_ids.append(temp_list)\n",
    "                aligned_column_labels.append(batch_column_labels[batch_id][c_id])\n",
    "\n",
    "        batch_aligned_question_ids.append(aligned_question_ids)\n",
    "        batch_aligned_table_name_ids.append(aligned_table_name_ids)\n",
    "        batch_aligned_column_info_ids.append(aligned_column_info_ids)\n",
    "        batch_aligned_table_labels.append(aligned_table_labels)\n",
    "        batch_aligned_column_labels.append(aligned_column_labels)\n",
    "\n",
    "    # update column number in each table (because some tables and columns are discarded)\n",
    "    for batch_id in range(batch_size):\n",
    "        if len(batch_column_number_in_each_table[batch_id]) > len(batch_aligned_table_labels[batch_id]):\n",
    "            batch_column_number_in_each_table[batch_id] = batch_column_number_in_each_table[batch_id][ : len(batch_aligned_table_labels[batch_id])]\n",
    "        \n",
    "        if sum(batch_column_number_in_each_table[batch_id]) > len(batch_aligned_column_labels[batch_id]):\n",
    "            truncated_column_number = sum(batch_column_number_in_each_table[batch_id]) - len(batch_aligned_column_labels[batch_id])\n",
    "            batch_column_number_in_each_table[batch_id][-1] -= truncated_column_number\n",
    "\n",
    "    encoder_input_ids = tokenized_inputs[\"input_ids\"]\n",
    "    encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"]\n",
    "    batch_aligned_column_labels = [torch.LongTensor(column_labels) for column_labels in batch_aligned_column_labels]\n",
    "    batch_aligned_table_labels = [torch.LongTensor(table_labels) for table_labels in batch_aligned_table_labels]\n",
    "\n",
    "    # print(\"\\n\".join(tokenizer.batch_decode(encoder_input_ids, skip_special_tokens = True)))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        encoder_input_ids = encoder_input_ids.cuda()\n",
    "        encoder_input_attention_mask = encoder_input_attention_mask.cuda()\n",
    "        batch_aligned_column_labels = [column_labels.cuda() for column_labels in batch_aligned_column_labels]\n",
    "        batch_aligned_table_labels = [table_labels.cuda() for table_labels in batch_aligned_table_labels]\n",
    "\n",
    "    return encoder_input_ids, encoder_input_attention_mask, \\\n",
    "        batch_aligned_column_labels, batch_aligned_table_labels, \\\n",
    "        batch_aligned_question_ids, batch_aligned_column_info_ids, \\\n",
    "        batch_aligned_table_name_ids, batch_column_number_in_each_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3460215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "    save_path,\n",
    "    add_prefix_space = True\n",
    ")\n",
    "\n",
    "dataset = ColumnAndTableClassifierDataset(\n",
    "    dir_ = dev_filepath,\n",
    "    use_contents = use_contents,\n",
    "    add_fk_info = add_fk_info\n",
    ")\n",
    "\n",
    "dataloder = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    collate_fn = lambda x: x\n",
    ")\n",
    "\n",
    "# initialize model\n",
    "model = MyClassifier(\n",
    "    model_name_or_path = save_path,\n",
    "    vocab_size = len(tokenizer),\n",
    "    mode = mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f48c442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyClassifier(\n",
      "  (plm_encoder): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50266, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (column_info_cls_head_linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (column_info_cls_head_linear2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (column_info_bilstm): LSTM(1024, 512, num_layers=2, bidirectional=True)\n",
      "  (column_info_linear_after_pooling): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (table_name_cls_head_linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (table_name_cls_head_linear2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (table_name_bilstm): LSTM(1024, 512, num_layers=2, bidirectional=True)\n",
      "  (table_name_linear_after_pooling): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "  (tanh): Tanh()\n",
      "  (table_column_cross_attention_layer): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load fine-tuned params\n",
    "model.load_state_dict(torch.load(os.path.join(save_path,\"dense_classifier.pt\"),\n",
    "                                 map_location=torch.device('cpu')))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "print(model.eval())\n",
    "\n",
    "table_labels_for_auc, column_labels_for_auc = [], []\n",
    "table_pred_probs_for_auc, column_pred_probs_for_auc = [], []\n",
    "\n",
    "returned_table_pred_probs, returned_column_pred_probs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a58233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_names_based_on_probs(probs, names):\n",
    "#     print(f\"probs = {probs}\")\n",
    "#     print(f\"names = {names}\")\n",
    "    sorted_lists = sorted(zip(probs, names))\n",
    "\n",
    "    sorted_table_probs = [x[0] for x in sorted_lists]\n",
    "    sorted_tables = [x[1] for x in sorted_lists]\n",
    "\n",
    "    sorted_table_probs.reverse()\n",
    "    sorted_tables.reverse()\n",
    "\n",
    "    return sorted_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c310588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "output_final = {}\n",
    "max_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4ec2031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 696/696 [15:49<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table auc: 0.6382781766775827\n",
      "column auc: 0.42589333719621886\n",
      "total auc: 1.0641715138738015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(dataloder):\n",
    "    \n",
    "    if batch[0][0] in list(output_final.keys()):\n",
    "        counter += 1\n",
    "        continue\n",
    "    \n",
    "    encoder_input_ids, encoder_input_attention_mask, \\\n",
    "        batch_column_labels, batch_table_labels, batch_aligned_question_ids, \\\n",
    "        batch_aligned_column_info_ids, batch_aligned_table_name_ids, \\\n",
    "        batch_column_number_in_each_table = prepare_batch_inputs_and_labels(batch, tokenizer)\n",
    "    \n",
    "    if DEBUG_FLAG: print(f\"encoder_input_ids - {encoder_input_ids}\")\n",
    "    if DEBUG_FLAG: print(f\"encoder_input_attention_mask - {encoder_input_attention_mask}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_outputs = model(\n",
    "            encoder_input_ids,\n",
    "            encoder_input_attention_mask,\n",
    "            batch_aligned_question_ids,\n",
    "            batch_aligned_column_info_ids,\n",
    "            batch_aligned_table_name_ids,\n",
    "            batch_column_number_in_each_table\n",
    "        )\n",
    "        \n",
    "    for batch_id, table_logits in enumerate(model_outputs[\"batch_table_name_cls_logits\"]):\n",
    "        table_pred_probs = torch.nn.functional.softmax(table_logits, dim = 1)\n",
    "        returned_table_pred_probs.append(table_pred_probs[:, 1].cpu().tolist())\n",
    "\n",
    "        table_pred_probs_for_auc.extend(table_pred_probs[:, 1].cpu().tolist())\n",
    "        table_labels_for_auc.extend(batch_table_labels[batch_id].cpu().tolist())\n",
    "        \n",
    "        get_table_pred_probs = table_pred_probs[:, 1].cpu().tolist()\n",
    "\n",
    "    for batch_id, column_logits in enumerate(model_outputs[\"batch_column_info_cls_logits\"]):\n",
    "        column_number_in_each_table = batch_column_number_in_each_table[batch_id]\n",
    "        column_pred_probs = torch.nn.functional.softmax(column_logits, dim = 1)\n",
    "        returned_column_pred_probs.append([column_pred_probs[:, 1].cpu().tolist()[sum(column_number_in_each_table[:table_id]):sum(column_number_in_each_table[:table_id+1])] \\\n",
    "            for table_id in range(len(column_number_in_each_table))])\n",
    "\n",
    "        column_pred_probs_for_auc.extend(column_pred_probs[:, 1].cpu().tolist())\n",
    "        column_labels_for_auc.extend(batch_column_labels[batch_id].cpu().tolist())\n",
    "        \n",
    "        get_col_pred_probs = column_pred_probs[:, 1].cpu().tolist()\n",
    "    \n",
    "    # table names and column names\n",
    "    table_names = batch[0][1]\n",
    "    col_names = batch[0][3]\n",
    "\n",
    "    # sort table names\n",
    "    sorted_tables = sort_names_based_on_probs(get_table_pred_probs, table_names)\n",
    "\n",
    "    # sort column names\n",
    "    table_col_dict = {}\n",
    "    init_id = 0\n",
    "    for idx, tab in enumerate(table_names):\n",
    "        columns = col_names[idx]\n",
    "        probs = get_col_pred_probs[init_id : (init_id + len(columns))]\n",
    "\n",
    "        sorted_columns = sort_names_based_on_probs(probs, columns)\n",
    "        table_col_dict[tab] = sorted_columns\n",
    "\n",
    "        init_id = len(columns)\n",
    "    \n",
    "    # create ranked db schema\n",
    "    db_scheme = ''\n",
    "    for table in sorted_tables:\n",
    "        db_scheme += (table + ' : ')\n",
    "\n",
    "        for idx, col1 in enumerate(table_col_dict[table]):\n",
    "    #         print(col1)\n",
    "            db_scheme += col1\n",
    "\n",
    "            if idx < len(table_col_dict[table])-1:\n",
    "                db_scheme += ' , '\n",
    "            else:\n",
    "                db_scheme += ' | '\n",
    "\n",
    "        db_scheme = db_scheme.replace(\"  \", ' ')\n",
    "    db_scheme = db_scheme[:-3]\n",
    "    \n",
    "    output_final[batch[0][0]] = db_scheme\n",
    "    \n",
    "    check_len = batch[0][0] + \" | \" + db_scheme\n",
    "    max_len = max(max_len, len(check_len.split()))\n",
    "        \n",
    "    counter += 1\n",
    "#     if counter>50: break\n",
    "\n",
    "    if counter % 50 == 0:\n",
    "        output_filepath = \"../data/resdsql_pre/preprocessed_dataset_test_db_schema.json\"\n",
    "        with open(output_filepath, \"w\") as fp:\n",
    "            json.dump(output_final, fp, indent=4)\n",
    "        \n",
    "if mode == \"eval\":\n",
    "    # calculate AUC score for table classification\n",
    "    table_auc = auc_metric(table_labels_for_auc, table_pred_probs_for_auc)\n",
    "    # calculate AUC score for column classification\n",
    "    column_auc = auc_metric(column_labels_for_auc, column_pred_probs_for_auc)\n",
    "    print(\"table auc:\", table_auc)\n",
    "    print(\"column auc:\", column_auc)\n",
    "    print(\"total auc:\", table_auc+column_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20371e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many heads of the departments are older than 56 ?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5b6063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4917433559894562, 0.4917435646057129], tensor([1, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_table_pred_probs, batch_table_labels[batch_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45eae052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 696)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2f18fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are all company names that have a corresponding movie directed in the year 1999? | movie : year , title , director , gross worldwide , budget million , movie id ( [FK] ) | book club : year , result , publisher , category , book title , author or editor , book club id ( [FK] ) | culture company : incorporated in , group equity shareholding , company name , book club id ( [FK] ) , movie id ( [FK] ) , type'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e92f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, dict)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_final.keys()), type(output_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424018c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24222856760025024,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076,\n",
       " 0.23681582510471344,\n",
       " 0.23681406676769257,\n",
       " 0.2792842388153076,\n",
       " 0.23681406676769257,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076,\n",
       " 0.2792842388153076]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_col_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2035a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# output_filepath = \"../data/resdsql_pre/preprocessed_dataset_train_db_schema.json\"\n",
    "# with open(output_filepath, \"w\") as fp:\n",
    "#     json.dump(output_final, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67fe0337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda20cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table_names = batch[0][1]\n",
    "col_names = batch[0][3]\n",
    "\n",
    "sorted_tables = sort_names_based_on_probs(table_pred_probs, table_names)\n",
    "\n",
    "table_col_dict = {}\n",
    "init_id = 0\n",
    "for idx, tab in enumerate(table_names):\n",
    "    columns = col_names[idx]\n",
    "    probs = column_pred_probs[init_id : (init_id + len(columns))]\n",
    "    \n",
    "    sorted_columns = sort_names_based_on_probs(probs, columns)\n",
    "    table_col_dict[tab] = sorted_columns\n",
    "    \n",
    "    init_id = len(columns)\n",
    "    \n",
    "db_scheme = ''\n",
    "for table in sorted_tables:\n",
    "    db_scheme += (table + ' : ')\n",
    "    \n",
    "    for idx, col1 in enumerate(table_col_dict[table]):\n",
    "#         print(col1)\n",
    "        db_scheme += col1\n",
    "        \n",
    "        if idx < len(table_col_dict[table])-1:\n",
    "            db_scheme += ' , '\n",
    "        else:\n",
    "            db_scheme += ' | '\n",
    "    \n",
    "    db_scheme = db_scheme.replace(\"  \", ' ')\n",
    "db_scheme = db_scheme[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ad786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba45fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "db_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116044a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_scheme[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ff62366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c180e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_outputs\n",
    "# encoder_input_ids[0]\n",
    "# encoder_input_attention_mask\n",
    "# batch_aligned_question_ids\n",
    "# batch_aligned_column_info_ids\n",
    "# batch_aligned_table_name_ids\n",
    "# batch_column_number_in_each_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43098387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "return returned_table_pred_probs, returned_column_pred_probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
