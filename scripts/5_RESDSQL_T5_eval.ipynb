{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09cb979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from text2sql_decoding_utils import decode_sqls\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "# from transformers.optimization import Adafactor\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "from load_dataset import Text2SQLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spider_metric.evaluator import EvaluateTool\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bd3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test(mode,\n",
    "          dev_filepath,\n",
    "          original_dev_filepath,\n",
    "          save_path,\n",
    "          db_path,\n",
    "          batch_size,\n",
    "          num_beams, num_return_sequences,\n",
    "          output,\n",
    "          seed, device):\n",
    "    \n",
    "    set_seed(seed)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = device\n",
    "\n",
    "    # initialize tokenizer\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(\n",
    "        save_path,\n",
    "        add_prefix_space = True\n",
    "    )\n",
    "    \n",
    "    if isinstance(tokenizer, T5TokenizerFast):\n",
    "        tokenizer.add_tokens([AddedToken(\" <=\"), AddedToken(\" <\")])\n",
    "    \n",
    "    dev_dataset = Text2SQLDataset(\n",
    "        dir_ = dev_filepath,\n",
    "        mode = mode\n",
    "    )\n",
    "\n",
    "    dev_dataloder = DataLoader(\n",
    "        dev_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = False,\n",
    "        collate_fn = lambda x: x,\n",
    "        drop_last = False\n",
    "    )\n",
    "\n",
    "    # initialize model\n",
    "    model = T5ForConditionalGeneration.from_pretrained(save_path)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    predict_sqls = []\n",
    "    \n",
    "    count = 0\n",
    "    for batch in tqdm(dev_dataloder):\n",
    "        batch_inputs = [data[0] for data in batch]\n",
    "        batch_db_ids = [data[1] for data in batch]\n",
    "        batch_tc_original = [data[2] for data in batch]\n",
    "\n",
    "        tokenized_inputs = tokenizer(\n",
    "            batch_inputs, \n",
    "            return_tensors=\"pt\",\n",
    "            padding = \"max_length\",\n",
    "            max_length = 512,\n",
    "            truncation = True\n",
    "        )\n",
    "        \n",
    "        encoder_input_ids = tokenized_inputs[\"input_ids\"]\n",
    "        encoder_input_attention_mask = tokenized_inputs[\"attention_mask\"]\n",
    "        if torch.cuda.is_available():\n",
    "            encoder_input_ids = encoder_input_ids.cuda()\n",
    "            encoder_input_attention_mask = encoder_input_attention_mask.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model.generate(\n",
    "                input_ids = encoder_input_ids,\n",
    "                attention_mask = encoder_input_attention_mask,\n",
    "                max_length = 256,\n",
    "                decoder_start_token_id = model.config.decoder_start_token_id,\n",
    "                num_beams = num_beams,\n",
    "                num_return_sequences = num_return_sequences\n",
    "            )\n",
    "\n",
    "            model_outputs = model_outputs.view(len(batch_inputs), num_return_sequences, model_outputs.shape[1])\n",
    "\n",
    "            predict_sqls += decode_sqls(\n",
    "                db_path, \n",
    "                model_outputs, \n",
    "                batch_db_ids, \n",
    "                batch_inputs, \n",
    "                tokenizer, \n",
    "                batch_tc_original\n",
    "            )\n",
    "        \n",
    "        count += 1\n",
    "        if count>50: break\n",
    "\n",
    "    new_dir = \"/\".join(output.split(\"/\")[:-1]).strip()\n",
    "    if new_dir != \"\":\n",
    "        os.makedirs(new_dir, exist_ok = True)\n",
    "    \n",
    "    # save results\n",
    "    with open(output, \"w\", encoding = 'utf-8') as f:\n",
    "        for pred in predict_sqls:\n",
    "            f.write(pred + \"\\n\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Text-to-SQL inference spends {}s.\".format(end_time-start_time))\n",
    "    \n",
    "    if mode == \"eval\":\n",
    "        # initialize evaluator\n",
    "        evaluator = EvaluateTool()\n",
    "        evaluator.register_golds(original_dev_filepath, db_path)\n",
    "        spider_metric_result = evaluator.evaluate(predict_sqls)\n",
    "        print('exact_match score: {}'.format(spider_metric_result[\"exact_match\"]))\n",
    "        print('exec score: {}'.format(spider_metric_result[\"exec\"]))\n",
    "    \n",
    "        return spider_metric_result[\"exact_match\"], spider_metric_result[\"exec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cc2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/696 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-SQL inference spends 1.719811201095581s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdev_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/resdsql_pre/preprocessed_dataset_test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_dev_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/split/spider_test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../spider_data/database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/text2sql/checkpoint-6500\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted_sql.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 104\u001b[0m, in \u001b[0;36m_test\u001b[0;34m(mode, dev_filepath, original_dev_filepath, save_path, db_path, batch_size, num_beams, num_return_sequences, output, seed, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m EvaluateTool()\n\u001b[1;32m    103\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mregister_golds(original_dev_filepath, db_path)\n\u001b[0;32m--> 104\u001b[0m spider_metric_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_sqls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact_match score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spider_metric_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/evaluator.py:60\u001b[0m, in \u001b[0;36mEvaluateTool.evaluate\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m     59\u001b[0m     exact_match \u001b[38;5;241m=\u001b[39m compute_exact_match_metric(preds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgolds)\n\u001b[0;32m---> 60\u001b[0m     test_suite \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_test_suite_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexact_match, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtest_suite}\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/spider_metric/spider_test_suite.py:49\u001b[0m, in \u001b[0;36mcompute_test_suite_metric\u001b[0;34m(predictions, references, db_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_one\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdb_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturn_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturn_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected evaluation error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/evaluation.py:643\u001b[0m, in \u001b[0;36mEvaluator.evaluate_one\u001b[0;34m(self, db_name, gold, predicted, turn_scores, idx)\u001b[0m\n\u001b[1;32m    629\u001b[0m         p_sql \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_units\u001b[39m\u001b[38;5;124m\"\u001b[39m: []},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    640\u001b[0m         }\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 643\u001b[0m     exec_score \u001b[38;5;241m=\u001b[39m \u001b[43meval_exec_match\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplug_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplug_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_distinct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_distinct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_for_each_datapoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exec_score:\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/spring23/cs685-NLP/project/notebooks/third_party/test_suite/exec_eval.py:240\u001b[0m, in \u001b[0;36meval_exec_match\u001b[0;34m(db, p_str, g_str, plug_value, keep_distinct, progress_bar_for_each_datapoint)\u001b[0m\n\u001b[1;32m    237\u001b[0m     ranger \u001b[38;5;241m=\u001b[39m db_paths\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m db_path \u001b[38;5;129;01min\u001b[39;00m ranger:\n\u001b[0;32m--> 240\u001b[0m     g_flag, g_denotation \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_on_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     p_flag, p_denotation \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(exec_on_db(db_path, pred))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# we should expect the gold to be succesfully executed on the database\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "_test(mode='eval',\n",
    "      dev_filepath=\"../data/resdsql_pre/preprocessed_dataset_test.json\",\n",
    "      original_dev_filepath=\"../data/split/spider_test.json\",\n",
    "      db_path = \"../spider_data/database\",\n",
    "      save_path=\"models/text2sql/checkpoint-6500\",\n",
    "      batch_size=1,\n",
    "      num_beams=2,\n",
    "      num_return_sequences=2,\n",
    "      output = \"predicted_sql.txt\",\n",
    "      seed=42,\n",
    "      device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2aab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
